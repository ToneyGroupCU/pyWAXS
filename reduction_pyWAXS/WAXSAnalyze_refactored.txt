##########################################################################################
## -- PSEUDOCODE LOGIC SEGMENT -- ##
# This will normalize the image, calculate SNR, generate random points,
# perform adaptive gradient ascent to find peaks, group them, and visualize them.

    # Normalize Intensity
    # Filter (Gaussian Noise)
    # Singular Value Decomposition (SVD) to remove noise and reconstruct peaks.
    # Find Peaks (Monte Carlo - Momentum Gradient Ascent)
    # Group Peak Points/Bin Peaks
        # Manual Regrouping Option
    # Tabulate Coordinates & Intensity of Peaks
        # Store Normalization, Filtering, SVD Compression, Search Algorithm (neighborhood) and Peak Position Data as a .json
    
    # -- Experiment Class
    # Predictive Algorithm for 'Best Initial Guess'
        # Input constraints on lattice parameters
        # Look for and tabulate multiples of peaks in q_xy 
        # Look for and tabulate multiples of peaks in q_z
        # Provide best guess with confidence and error for the lattice constants
        # Select set of peaks to evaluate sigma values for azimuthal smearing
    # Load CIFs into DiffSim object
    # Load 'Best Initial Guess' to match appropriate CIF and orientation parameters
    # Simulate Bragg Peak Positions in CIFs (no intensity)
        # Load possible CIFs to test against a, b, c, alpha, beta, gamma values
            # Comparator Bragg Peak Simulation (Compute Crystal)
        # Best match for position, simulate intensities and smearing from initial guesses.
            # diffraction .py
   
   '''
    # ATTRIBUTES:
        # self.caked_data_np, self.recip_data_np, self.qz_np, self.qxy_np, self.chi_np, self.qr_np = None, None, None, None, None, None # datatypes: numpy arrays
        # self.peak_positions_pixel = None
        # self.peak_positions_coords = None
        # self.apply_detector_corrections()
    '''

    '''
        def find_and_sort_gaps(self, img):
        """
        Find and sort gaps based on their length. Both horizontal and vertical gaps are considered.
        """
        gap_indices = np.argwhere(np.isnan(img.values))
        if len(gap_indices) == 0:
            return None

        vertical_gaps = {}
        horizontal_gaps = {}

        for x, y in gap_indices:
            # Check vertical gaps
            length = 0
            temp_y = y
            while temp_y < img.shape[1] and np.isnan(img.values[x, temp_y]):
                length += 1
                temp_y += 1

            if length > 0:
                vertical_gaps[(x, y)] = length

            # Check horizontal gaps
            length = 0
            temp_x = x
            while temp_x < img.shape[0] and np.isnan(img.values[temp_x, y]):
                length += 1
                temp_x += 1

            if length > 0:
                horizontal_gaps[(x, y)] = length

        # Sort gaps based on their length
        sorted_vertical_gaps = sorted(vertical_gaps.items(), key=lambda x: x[1])
        sorted_horizontal_gaps = sorted(horizontal_gaps.items(), key=lambda x: x[1])

        return sorted_vertical_gaps, sorted_horizontal_gaps

    def fill_smallest_gaps(self, img, sorted_vertical_gaps, sorted_horizontal_gaps):
        """
        Fill the smallest gaps in both vertical and horizontal directions.
        """
        if sorted_vertical_gaps:
            smallest_vertical_gap = sorted_vertical_gaps[0]
            start_x, start_y = smallest_vertical_gap[0]
            length = smallest_vertical_gap[1]

            top_neighbor = img.values[start_x - 1, start_y] if start_x > 0 else 0
            bottom_neighbor = img.values[start_x + length, start_y] if start_x + length < img.shape[0] else 0

            fill_value = (top_neighbor + bottom_neighbor) / 2
            img.values[start_x:start_x+length, start_y] = fill_value

        if sorted_horizontal_gaps:
            smallest_horizontal_gap = sorted_horizontal_gaps[0]
            start_x, start_y = smallest_horizontal_gap[0]
            length = smallest_horizontal_gap[1]

            left_neighbor = img.values[start_x, start_y - 1] if start_y > 0 else 0
            right_neighbor = img.values[start_x, start_y + length] if start_y + length < img.shape[1] else 0

            fill_value = (left_neighbor + right_neighbor) / 2
            img.values[start_x, start_y:start_y+length] = fill_value

    def fill_gaps(self, img):
        """
        Recursively fill gaps in the image using linear interpolation, focusing on the smallest gaps first.
        """
        processed_gaps = set()  # To keep track of gaps that have been processed
        
        while True:
            sorted_gaps = self.find_and_sort_gaps(img)
            if sorted_gaps is None:
                break

            sorted_vertical_gaps, sorted_horizontal_gaps = sorted_gaps

            # Fill the smallest vertical gap
            for gap_start, length in sorted_vertical_gaps:
                if gap_start not in processed_gaps:
                    start_x, start_y = gap_start

                    top_neighbor = img.values[start_x - 1, start_y] if start_x > 0 else 0
                    bottom_neighbor = img.values[start_x + length, start_y] if start_x + length < img.shape[0] else 0

                    fill_value = (top_neighbor + bottom_neighbor) / 2
                    img.values[start_x:start_x + length, start_y] = fill_value

                    processed_gaps.add(gap_start)
                    break

            # Fill the smallest horizontal gap
            for gap_start, length in sorted_horizontal_gaps:
                if gap_start not in processed_gaps:
                    start_x, start_y = gap_start

                    left_neighbor = img.values[start_x, start_y - 1] if start_y > 0 else 0
                    right_neighbor = img.values[start_x, start_y + length] if start_y + length < img.shape[1] else 0

                    fill_value = (left_neighbor + right_neighbor) / 2
                    img.values[start_x, start_y:start_y + length] = fill_value

                    processed_gaps.add(gap_start)
                    break
    '''

    '''
    def initial_peak_identification(self, img_xr, sigma1, sigma2, threshold):
        img_smooth1 = gaussian_filter(img_xr.fillna(0).values, sigma=sigma1)
        img_smooth2 = gaussian_filter(img_xr.fillna(0).values, sigma=sigma2)
        DoG = img_smooth1 - img_smooth2  # Difference of Gaussians Value
        
        # Apply NaN mask to DoG using the mask attribute if present
        mask = img_xr.attrs.get('mask', None)
        if mask is not None:
            maskedDoG = np.where(mask == 0, np.nan, DoG)
        else:
            maskedDoG = DoG

        self.DoG = xr.DataArray(DoG, coords=img_xr.coords, dims=img_xr.dims)
        self.maskedDoG = xr.DataArray(maskedDoG, coords=img_xr.coords, dims=img_xr.dims)
        return np.where(DoG >= threshold, DoG, np.nan)
    '''

    '''
    def find_peaks_DoG(self, img_xr, sigma1=1.0, sigma2=2.0, threshold=0.006, eps=1, min_samples=2, struct_elem=None):
        if sigma2 <= sigma1:
            raise ValueError("sigma2 must be greater than sigma1.")
            
        # Normalize to 1 at maximum value, accounting for NaNs
        img_normalized = img_xr / np.nanmax(img_xr.values)
        
        # Apply Gaussian filters
        img_smooth1 = gaussian_filter(img_normalized.fillna(0).values, sigma=sigma1)
        img_smooth2 = gaussian_filter(img_normalized.fillna(0).values, sigma=sigma2)
        
        # Compute Difference of Gaussians
        DoG = img_smooth1 - img_smooth2
        
        # Identify initial peaks
        initial_peaks = np.where(DoG >= threshold, DoG, np.nan)
        
        # Handle Edge Cases (same as before)
        edge_mask = np.isnan(gaussian_filter(img_xr.fillna(0).values, sigma=1))
        initial_peaks[edge_mask] = np.nan

        # Morphological closing to bridge small gaps (optional)
        if struct_elem is not None:
            initial_peaks = binary_closing(initial_peaks, structure=struct_elem)
        
        print("DoG and initial_peaks are the same: ", np.array_equal(DoG, initial_peaks))

        # DBSCAN for clustering local maxima (same as before)
        peak_coords = np.column_stack(np.where(~np.isnan(initial_peaks)))
        if peak_coords.shape[0] > 0:
            clustering = DBSCAN(eps=eps, min_samples=min_samples).fit(peak_coords)
            cluster_labels = clustering.labels_
            
            for cluster_id in set(cluster_labels):
                if cluster_id == -1:
                    continue
                coords_in_cluster = peak_coords[cluster_labels == cluster_id]
                
                # Find the local maxima within the cluster instead of median
                intensities = DoG[coords_in_cluster[:, 0], coords_in_cluster[:, 1]]
                max_idx = np.argmax(intensities)
                max_coord = coords_in_cluster[max_idx]
                
                # Nullify other peaks in the cluster
                initial_peaks[coords_in_cluster[:, 0], coords_in_cluster[:, 1]] = np.nan
                
                # Store the local maxima
                initial_peaks[max_coord[0], max_coord[1]] = DoG[max_coord[0], max_coord[1]]

        # Initialize output DataArray for peaks
        peaks_xr = xr.DataArray(initial_peaks, coords=img_xr.coords, dims=img_xr.dims)
        
        # Store peak information in the attrs attribute of the original DataArray
        img_xr.attrs['peaks'] = peaks_xr
        
        return img_xr
    '''

    '''
    def find_peaks_DoG(self, img_xr, sigma1=1.0, sigma2=2.0, threshold=0.2, eps=3, min_samples=2):
        if sigma2 <= sigma1:
            raise ValueError("sigma2 must be greater than sigma1.")
            
        # Normalize to 1 at maximum value, accounting for NaNs
        img_normalized = img_xr / np.nanmax(img_xr.values)
        
        # Apply Gaussian filters
        img_smooth1 = gaussian_filter(img_normalized.fillna(0).values, sigma=sigma1)
        img_smooth2 = gaussian_filter(img_normalized.fillna(0).values, sigma=sigma2)
        
        # Compute Difference of Gaussians
        DoG = img_smooth1 - img_smooth2
        
        # Identify initial peaks
        initial_peaks = np.where(DoG >= threshold, DoG, np.nan)
        
        # Handle Edge Cases
        edge_mask = np.isnan(gaussian_filter(img_xr.fillna(0).values, sigma=1))
        initial_peaks[edge_mask] = np.nan
        
        # DBSCAN for clustering local maxima
        peak_coords = np.column_stack(np.where(~np.isnan(initial_peaks)))
        if peak_coords.shape[0] > 0:
            clustering = DBSCAN(eps=eps, min_samples=min_samples).fit(peak_coords)
            cluster_labels = clustering.labels_
            
            for cluster_id in set(cluster_labels):
                if cluster_id == -1:
                    continue
                coords_in_cluster = peak_coords[cluster_labels == cluster_id]
                median_coord = np.median(coords_in_cluster, axis=0).astype(int)
                initial_peaks[coords_in_cluster[:, 0], coords_in_cluster[:, 1]] = np.nan
                initial_peaks[median_coord[0], median_coord[1]] = DoG[median_coord[0], median_coord[1]]
                
        # Initialize output DataArray for peaks
        peaks_xr = xr.DataArray(initial_peaks, coords=img_xr.coords, dims=img_xr.dims)
        
        # Store peak information in the attrs attribute of the original DataArray
        img_xr.attrs['peaks'] = peaks_xr
        
        return img_xr
        '''

    '''
    def brute_force_interpolation(self, data_array, axis, pixelcount):
        new_data = data_array.copy(deep=True)
        other_axis = [dim for dim in data_array.dims if dim != axis][0]
        
        for i in range(len(data_array[other_axis].values)):
            intensity_values = data_array.isel({other_axis: i}).values
            start_gap = None
            end_gap = None
            gap_length = 0
            
            for j in range(len(intensity_values)):
                if np.isnan(intensity_values[j]) or intensity_values[j] == 0:
                    if start_gap is None:
                        start_gap = j - 1
                    gap_length += 1
                else:
                    if start_gap is not None:
                        end_gap = j
                        if 0 < gap_length <= pixelcount:
                            interp_values = np.linspace(intensity_values[start_gap], intensity_values[end_gap], gap_length + 2)
                            new_data.isel({other_axis: i}).values[start_gap + 1:end_gap] = interp_values[1:-1]
                        
                        start_gap = None
                        end_gap = None
                        gap_length = 0
                        
        return new_data
    '''
    
    '''
    def brute_force_interpolation(self, data_array, pixelthreshold_range):
        new_data = data_array.copy(deep=True)
        
        for pc in pixelthreshold_range:
            for axis in data_array.dims:
                other_axis = [dim for dim in data_array.dims if dim != axis][0]
                
                for i in range(len(data_array[other_axis].values)):
                    intensity_values = data_array.isel({other_axis: i}).values
                    start_gap = None
                    gap_length = 0

                    for j in range(len(intensity_values)):
                        if np.isnan(intensity_values[j]) or intensity_values[j] == 0:
                            if start_gap is None and j > 0:
                                start_gap = j - 1
                            gap_length += 1
                        else:
                            if start_gap is not None:
                                end_gap = j
                                if 0 < gap_length <= pc and end_gap < len(intensity_values) - 1:
                                    interp_values = np.linspace(intensity_values[start_gap], intensity_values[end_gap], gap_length + 2)
                                    if len(interp_values[1:-1]) == end_gap - start_gap - 1:
                                        new_data.isel({other_axis: i}).values[start_gap + 1:end_gap] = interp_values[1:-1]

                                start_gap = None
                                gap_length = 0
                        
        return new_data
    '''

## --- IMAGE INTERPOLATION  --- ##
    def brute_force_interpolate(self, img: xr.DataArray, gap_threshold: int = 5) -> xr.DataArray:
        """
        Brute-force interpolation method to fill gaps in an image.
        
        Parameters:
            img (xr.DataArray): Input image data
            gap_threshold (int): Maximum size of gaps to interpolate
        
        Returns:
            xr.DataArray: Interpolated image
        """
        interpolated_img = img.copy()
        
        rows, cols = img.shape
        
        for col in range(cols):
            gap_start = None
            for row in range(rows):
                if img[row, col] != 0 and gap_start is not None:
                    gap_end = row
                    
                    # Check if the gap size is within the threshold
                    if gap_end - gap_start <= gap_threshold:
                        # Interpolate
                        interpolated_img[gap_start:gap_end, col] = np.interp(
                            np.arange(gap_start, gap_end),
                            [gap_start - 1, gap_end],
                            [img[gap_start - 1, col], img[gap_end, col]]
                        )
                    
                    gap_start = None
                elif img[row, col] == 0 and gap_start is None:
                    gap_start = row
                    
        return interpolated_img
    '''
    
    '''
    def normalize_image(self, img=None, normalizerecip=False):
        # Check for invalid or incompatible types
        if img is None:
            if self.reciptiff_xr is None:
                raise ValueError("Reciprocal space image data is not available.")
            img = self.reciptiff_xr

        if not isinstance(img, (np.ndarray, xr.DataArray)):
            raise ValueError("The input image is not of a compatible type.")

        # Initialize original attributes
        original_attrs = {}

        # Handle xarray DataArray
        if isinstance(img, xr.DataArray):
            img_values = img.values
            original_attrs = img.attrs.copy()
            data_type = 'DataArray'
        else:
            img_values = img
            data_type = 'numpy'

        # Perform normalization
        max_val = np.max(img_values)
        if max_val <= 0:
            raise ValueError("Image maximum intensity is zero or negative, cannot normalize.")

        normalized_img_values = img_values / max_val

        # Create xarray DataArray and set attributes
        normalized_img = xr.DataArray(normalized_img_values, coords=img.coords if isinstance(img, xr.DataArray) else None, dims=img.dims if isinstance(img, xr.DataArray) else None)
        normalized_img.attrs.update(original_attrs)
        normalized_img.attrs['original_name'] = inspect.currentframe().f_back.f_locals.get('img', 'unknown')
        normalized_img.attrs['original_type'] = data_type

        # Save to class attribute
        self.normalized_img = normalized_img

        if normalizerecip:
            self.reciptiff_xr.values = normalized_img_values
            self.reciptiff_xr.attrs['normalized'] = True

        return normalized_img
    '''

    '''
    def interpolate_masked_image(img, mask, q_z_center, q_r_tolerance=5, num_points=40, method='linear'):
            """
            Interpolate masked regions in an image considering a polar coordinate framework (qr, chi).
            
            Parameters:
                img (np.ndarray): Input image with masked regions.
                mask (np.ndarray): Boolean mask indicating the masked regions in the image.
                q_z_center (tuple): The (x, y) coordinate of the origin (0, 0) in Cartesian coordinates.
                q_r_tolerance (float): Tolerance for considering pixels as similar in q_r value.
                num_points (int): Number of points to consider when fitting Gaussian across the q_z axis.
                method (str): Interpolation method ('linear', 'cubic', etc.).
                
            Returns:
                np.ndarray: Interpolated image.
            """
            
            # Get indices of non-masked and masked pixels
            non_masked_indices = np.column_stack(np.where(mask))
            masked_indices = np.column_stack(np.where(~mask))
            
            # Translate indices to Cartesian coordinates centered at q_z_center
            non_masked_coords = non_masked_indices - np.array(q_z_center)
            masked_coords = masked_indices - np.array(q_z_center)
            
            # Compute q_r values for non-masked and masked coordinates
            q_r_non_masked = np.linalg.norm(non_masked_coords, axis=1)
            q_r_masked = np.linalg.norm(masked_coords, axis=1)
            
            # Initialize interpolated image
            interpolated_img = img.copy()
            
            # Interpolate masked pixels
            for i, (x, y) in enumerate(masked_indices):
                q_r_value = q_r_masked[i]
                
                # Find non-masked pixels within the q_r tolerance
                within_tolerance = np.abs(q_r_non_masked - q_r_value) <= q_r_tolerance
                if np.sum(within_tolerance) == 0:
                    continue  # No points within tolerance to interpolate
                
                # Interpolate pixel value
                points_to_use = non_masked_indices[within_tolerance]
                values_to_use = img[points_to_use[:, 0], points_to_use[:, 1]]
                interpolated_value = griddata(points_to_use, values_to_use, (x, y), method=method)
                interpolated_img[x, y] = interpolated_value
            
            # Fit a Gaussian profile across the q_z axis (chi = 0)
            q_z_x, q_z_y = q_z_center
            x_indices = np.arange(q_z_x - num_points, q_z_x + num_points + 1)
            y_indices = np.full_like(x_indices, q_z_y)
            gaussian_points = img[x_indices, y_indices]
            
            # Fit Gaussian and interpolate across q_z axis
            # Here, you would fit a Gaussian model to gaussian_points and populate the q_z axis
            # For demonstration, the mean value is used
            interpolated_img[q_z_x - num_points:q_z_x + num_points + 1, q_z_y] = np.mean(gaussian_points)
            
            return interpolated_img
    '''

    '''
# -- Image Smoothing Algorithm
    def smooth_image(self, img, method: str = 'gaussian', **kwargs) -> xr.DataArray:
        """
        Smooth the input image using the specified method and exclude zero-intensity regions.
        
        Parameters:
            img (xr.DataArray or np.ndarray): Input image to be smoothed.
            method (str): The smoothing method to use ('gaussian', 'bilateral', 'total_variation', 'anisotropic').
            **kwargs: Additional parameters for the smoothing method.
            
        Returns:
            xr.DataArray: Smoothed image with the same shape as the input.
        """
        
        # Convert to xarray if input is a numpy array
        if isinstance(img, np.ndarray):
            img = xr.DataArray(img)
            
        # Create a mask to exclude zero-intensity regions
        mask = img != 0
        
        # Backup original dtype
        original_dtype = img.dtype
        
        if method == 'gaussian':
            sigma = kwargs.get('sigma', 1)
            smoothed = gaussian_filter(img.where(mask), sigma)
        elif method == 'bilateral':
            sigma_color = kwargs.get('sigma_color', 0.05)
            sigma_spatial = kwargs.get('sigma_spatial', 15)
            smoothed = denoise_bilateral(img.where(mask).values, sigma_color=sigma_color, sigma_spatial=sigma_spatial, multichannel=False)
        elif method == 'total_variation':
            weight = kwargs.get('weight', 0.1)
            smoothed = denoise_tv_chambolle(img.where(mask).values, weight=weight)
        elif method == 'anisotropic':
            smoothed = img.where(mask).copy()
        else:
            raise ValueError("Invalid method. Choose from 'gaussian', 'bilateral', 'total_variation', 'anisotropic'.")
        
        smoothed = xr.DataArray(smoothed, coords=img.coords, dims=img.dims)
        self.smoothed_img = smoothed.astype(original_dtype)
        return self.smoothed_img
    '''

    '''
        def cartesian_to_polar(q_xy, q_z):
        """
        Convert Cartesian coordinates (q_xy, q_z) to polar coordinates (q_r, chi).
        
        Parameters:
            q_xy (np.ndarray): Array of in-plane momentum transfer values.
            q_z (np.ndarray): Array of out-of-plane momentum transfer values.
            
        Returns:
            q_r (np.ndarray): Array of radial distance values.
            chi (np.ndarray): Array of angle values in degrees.
        """
        q_r = np.sqrt(q_xy ** 2 + q_z ** 2)
        chi = np.degrees(np.arctan2(q_xy, q_z))
        return q_r, chi

# - This doesn't work...
    def interpolate_image_radially(self, img: xr.DataArray, pixel_tolerance: float = 0.1) -> xr.DataArray:
        # Step 1: Conversion to Polar Coordinates
        q_xy, q_z = np.meshgrid(img.coords['q_xy'], img.coords['q_z'])
        q_r = np.sqrt(q_xy**2 + q_z**2)
        chi = np.arctan2(q_xy, q_z)

        # Step 2: Masking
        mask = img != 0

        # Create KDTree for efficient spatial search
        coords = np.column_stack((q_r[mask], chi[mask]))
        tree = KDTree(coords)

        # Step 3: Interpolation along q_r
        zero_pixels = np.column_stack((q_r[~mask], chi[~mask]))
        interpolated_values = np.zeros(zero_pixels.shape[0])

        # Batch queries for KD-Tree
        idx_list = tree.query_radius(zero_pixels, pixel_tolerance)
        
        for i, idx in enumerate(idx_list):
            if len(idx) == 0:
                continue  # Skip if no neighbors found
            neighbors = coords[idx]
            # Convert neighbors to original indices in img.values
            original_indices = np.array(np.where(mask)).T[idx]
            values = img.values[original_indices[:, 0], original_indices[:, 1]]
            interpolated_values[i] = np.mean(values)

        # Step 4: Special Interpolation at q_z = 0
        qz_zero_pixels = zero_pixels[np.isclose(zero_pixels[:, 1], 0, atol=1e-6)]
        
        # Batch query for special interpolation
        idx_list = tree.query_radius(qz_zero_pixels, pixel_tolerance)
        
        for i, idx in enumerate(idx_list):
            q = qz_zero_pixels[i, 0]
            neighbors = coords[idx]
            values = img.values[(neighbors[:, 0], neighbors[:, 1])]

            # Fit Gaussian
            popt, _ = curve_fit(self.gaussian, neighbors[:, 0], values)
            interpolated_values[qz_zero_pixels[:, 0] == q] = self.gaussian(q, *popt)

        # Step 5: Apply Interpolation
        img.values[~mask] = interpolated_values
        
        return img
    '''


'''
# -- Image Smoothing Algorithm
    def smooth_image(self, img, method: str = 'gaussian', sigma: float = 1.0, **kwargs) -> xr.DataArray:
        """
        Smooth the input image using the specified method.

        Parameters:
            img (xarray.DataArray or np.ndarray): Input image to be smoothed.
            method (str): The smoothing method to use ('gaussian', 'bilateral', 'total_variation', 'anisotropic').
            sigma (float): Sigma value for Gaussian smoothing. Default is 1.0.
            **kwargs: Additional parameters for the smoothing method.

        Returns:
            xarray.DataArray: Smoothed image.
        """
        
        # Check if input is xarray DataArray, and keep track
        is_xarray = False
        if isinstance(img, xr.DataArray):
            is_xarray = True
            original_coords = img.coords
            original_attrs = img.attrs
            img = img.values
        else:
            if not isinstance(img, np.ndarray):
                raise ValueError("Input must be either an xarray DataArray or a numpy array.")

        original_dtype = img.dtype

        # Perform smoothing
        if method == 'gaussian':
            smoothed = gaussian_filter(img, sigma)
        elif method == 'bilateral':
            sigma_color = kwargs.get('sigma_color', 0.1)
            sigma_spatial = kwargs.get('sigma_spatial', 15)
            smoothed = denoise_bilateral(img, sigma_color=sigma_color, sigma_spatial=sigma_spatial, multichannel=False)
        elif method == 'total_variation':
            weight = kwargs.get('weight', 0.1)
            smoothed = denoise_tv_chambolle(img, weight=weight)
        elif method == 'anisotropic':
            # Placeholder for anisotropic diffusion method (needs to be implemented)
            smoothed = img.copy()
        else:
            raise ValueError("Invalid method. Choose from 'gaussian', 'bilateral', 'total_variation', 'anisotropic'.")

        # Convert the smoothed image back to xarray DataArray if original input was xarray
        if is_xarray:
            smoothed = xr.DataArray(smoothed, coords=original_coords, attrs=original_attrs)

        self.smoothed_img = smoothed

        return self.smoothed_img

#     def smooth_image(self, img: np.ndarray, method: str = 'gaussian', **kwargs) -> np.ndarray:
#         """
#         Smooth the input image using the specified method.
        
#         Parameters:
#             img (np.ndarray): Input image to be smoothed.
#             method (str): The smoothing method to use ('gaussian', 'bilateral', 'total_variation', 'anisotropic').
#             **kwargs: Additional parameters for the smoothing method.
            
#         Returns:
#             np.ndarray: Smoothed image with the same data type and shape as the input.
#         """
#         original_dtype = img.dtype
        
#         if method == 'gaussian':
#             sigma = kwargs.get('sigma', 1)
#             smoothed = gaussian_filter(img, sigma)
#         elif method == 'bilateral':
#             print('This method is broken...') # note to fix.
#             sigma_color = kwargs.get('sigma_color', 0.05)
#             sigma_spatial = kwargs.get('sigma_spatial', 15)
#             smoothed = denoise_bilateral(img, sigma_color=sigma_color, sigma_spatial=sigma_spatial, multichannel=False)
#         elif method == 'total_variation':
#             weight = kwargs.get('weight', 0.1)
#             smoothed = denoise_tv_chambolle(img, weight=weight)
#         elif method == 'anisotropic':
#             # Placeholder for anisotropic diffusion method (needs to be implemented)
#             smoothed = img.copy()
#         else:
#             raise ValueError("Invalid method. Choose from 'gaussian', 'bilateral', 'total_variation', 'anisotropic'.")
        
#         self.smoothed_img = smoothed.astype(original_dtype)

#         # Convert the smoothed image back to the original data type
#         # return smoothed.astype(original_dtype)
#         return self.smoothed_img


# -- Calculating Signal-to-Noise Ratio (Internal)
    def calculate_SNR_for_class(self):
        """
        Calculate the Signal-to-Noise Ratio (SNR) for each xarray DataArray in the class.
        The SNR is stored as an attribute for each DataArray.
        """
        for attr_name in ['rawtiff_xr', 'reciptiff_xr', 'cakedtiff_xr']:
            xarray_obj = getattr(self, attr_name, None)
            if xarray_obj is not None:
                mean_val = np.mean(xarray_obj.values)
                std_val = np.std(xarray_obj.values)
                snr = mean_val / std_val if std_val != 0 else 0
                xarray_obj.attrs['SNR'] = snr

    def calculate_SNR(self, xarray_obj):
        """
        Calculate the Signal-to-Noise Ratio (SNR) for an external xarray DataArray or numpy array.
        The SNR is stored as a temporary attribute 'snrtemp'.

        Parameters:
            xarray_obj (xarray.DataArray or np.ndarray): The DataArray or numpy array for which to calculate SNR.

        Returns:
            None
        """
        if not isinstance(xarray_obj, (xr.DataArray, np.ndarray)):
            raise ValueError("Input must be either an xarray DataArray or a numpy array.")
        
        # If the input is a numpy array, convert it to xarray DataArray
        if isinstance(xarray_obj, np.ndarray):
            xarray_obj = xr.DataArray(xarray_obj)
        
        mean_val = np.mean(xarray_obj.values)
        std_val = np.std(xarray_obj.values)
        snr = mean_val / std_val if std_val != 0 else 0
        xarray_obj.attrs['SNR_temp'] = snr
        self.snrtemp = snr

        return xarray_obj
    '''

'''
# def calculate_SNR(self):
    #     if not hasattr(self, 'normalized_img'):
    #         raise AttributeError("'WAXSAnalyze' object has no attribute 'normalized_img'. Run 'normalize_image()' first.")
    #     self.snr = np.mean(self.normalized_img) / np.std(self.normalized_img)

# def normalize_image(self):
    #     img = self.reciptiff_xr.values.copy()
    #     max_val = np.max(img)
        
    #     if max_val <= 0:
    #         raise ValueError("Image maximum intensity is zero or negative, cannot normalize.")
        
    #     self.normalized_img = img / max_val
    #     # self.reciptiff_xr.values = self.normalized_img
        
    #     # return self.reciptiff_xr  # return the xarray DataArray
    #     return self.normalized_img

  # def display_image(self, img: np.ndarray, title: str = 'Image', cmap: str = 'jet', coords: dict = None):
    #     """
    #     Display the image using matplotlib.

    #     Parameters:
    #         img (np.ndarray): Image to be displayed.
    #         title (str): Title of the plot.
    #         cmap (str): Colormap to be used.
    #         coords (dict): Coordinate system to be used for plotting.

    #     Returns:
    #         None
    #     """
    #     plt.close('all')
    #     vmin = np.nanpercentile(img, 10)
    #     vmax = np.nanpercentile(img, 99)
    #     plt.imshow(np.flipud(img), 
    #                cmap='jet', 
    #                vmin=vmin, 
    #                vmax=vmax, 
    #                extent=[coords['x_min'], 
    #                        coords['x_max'], 
    #                        coords['y_min'], 
    #                        coords['y_max']])
    #     plt.title(title)
    #     plt.xlabel('qxy')
    #     plt.ylabel('qz')
    #     plt.colorbar()
    #     plt.show()

    def createSampleDictionary(self, root_folder):
        """
        Loads and creates a sample dictionary from a root folder path.
        The dictionary will contain: sample name, scanID list, series scanID list, 
        a pathlib object variable for each sample's data folder (which contains the /maxs/raw/ subfolders),
        and time_start and exposure_time for each series of scans.
        
        The method uses alias mappings to identify important metadata from the filenames:
        SCAN ID : Defines the scan ID number in the convention used at 11-BM (CMS), specific to a single shot exposure or time series.
            aliases : scan_id: 'scanid', 'id', 'scannum', 'scan', 'scan_id', 'scan_ID'
        SERIES NUMBER : Within a series (fixed SCAN ID), the exposure number in the series with respect to the starting TIME START (clocktime)
            aliases : series_number: 'seriesnum', 'seriesid', 'series_id', 'series_ID', 'series', 'series_number', 'series_num'
        TIME START : Also generically referred to as CLOCK TIME, logs the start of the exposure or series acquisition. This time is constant for all exposures within a series.
            aliases : time_start: 'start_time', 'starttime', 'start', 'clocktime', 'clock', 'clockpos', 'clock_time', 'time', 'time_start'
        EXPOSURE TIME : The duration of a single shot or exposure, either in a single image or within a series.
            aliases : 'exptime', 'exp_time', 'exposuretime', 'etime', 'exp', 'expt', 'exposure_time'
        """

        # Ensure the root_folder is a pathlib.Path object
        self.root_folder = pathlib.Path(root_folder)
        if not self.root_folder.is_dir():
            raise ValueError(f"Directory {self.root_folder} does not exist.")
        
        # Initialize the sample dictionary
        sample_dict = {}
        
        # Alias mappings for scan_id, series_number, time_start, and exposure_time
        scan_id_aliases = ['scanid', 'id', 'scannum', 'scan', 'scan_id', 'scan_ID']
        series_number_aliases = ['seriesnum', 'seriesid', 'series_id', 'series_ID', 'series', 'series_number', 'series_num']
        time_start_aliases = ['start_time', 'starttime', 'start', 'clocktime', 'clock', 'clockpos', 'clock_time', 'time', 'time_start']
        exposure_time_aliases = ['exptime', 'exp_time', 'exposuretime', 'etime', 'exp', 'expt', 'exposure_time']

        # Identify the indices of the required metadata in the naming scheme
        for idx, alias in enumerate(self.md_naming_scheme):
            if alias.lower() in [alias.lower() for alias in scan_id_aliases]:
                self.scan_id_index = idx
            if alias.lower() in [alias.lower() for alias in series_number_aliases]:
                self.series_number_index = idx

        if self.scan_id_index is None or self.series_number_index is None:
            raise ValueError('md_naming_scheme does not contain keys for scan_id or series_number.')

        # Update sample_dict with new information
        for sample_folder in self.root_folder.iterdir():
            if sample_folder.is_dir():
                # Confirm that this is a sample folder by checking for /maxs/raw/ subfolder
                maxs_raw_dir = sample_folder / 'maxs' / 'raw'
                if maxs_raw_dir.is_dir():
                    # Sample folder checks out, extract scan_id, series_number, time_start, and exposure_time
                    sample_name = sample_folder.name
                    scan_list = []
                    series_list = {}  # Initialize series_list as an empty dictionary
                    
                    for image_file in maxs_raw_dir.glob('*'):
                        # Load metadata from image
                        metadata = self.loadMd(image_file)
                        
                        # Lowercase all metadata keys for case insensitivity
                        metadata_lower = {k.lower(): v for k, v in metadata.items()}
                        
                        # Find and store scan_id, series_number, time_start, and exposure_time
                        scan_id = metadata_lower.get(self.md_naming_scheme[self.scan_id_index].lower())
                        series_number = metadata_lower.get(self.md_naming_scheme[self.series_number_index].lower())
                        time_start = next((metadata_lower[key] for key in metadata_lower if key in time_start_aliases), None)
                        exposure_time = next((metadata_lower[key] for key in metadata_lower if key in exposure_time_aliases), None)

                        # Add them to our lists
                        scan_list.append(scan_id)
                        
                        # Check if scan_id is in series_list, if not, create a new list
                        if scan_id not in series_list:
                            series_list[scan_id] = []

                        series_list[scan_id].append((series_number, time_start, exposure_time))
                    
                    # Store data in dictionary
                    sample_dict[sample_name] = {
                        'scanlist': scan_list,
                        'serieslist': series_list,
                        'path': sample_folder
                    }

        self.sample_dict = sample_dict
        return sample_dict

    def selectSampleAndSeries(self):
            """
            Prompts the user to select a sample and one or more series of scans from that sample.
            The user can choose to select all series of scans.
            The selections will be stored as the 'selected_series' attribute and returned.
            """
            # Check if sample_dict has been generated
            if not self.sample_dict:
                print("Error: Sample dictionary has not been generated. Please run createSampleDictionary() first.")
                return

            while True:
                # Show the user a list of sample names and get their selection
                print("Please select a sample (or 'q' to exit):")
                sample_names = list(self.sample_dict.keys())
                for i, sample_name in enumerate(sample_names, 1):
                    print(f"[{i}] {sample_name}")
                print("[q] Exit")
                selection = input("Enter the number of your choice: ")
                if selection.lower() == 'q':
                    print("Exiting selection.")
                    return self.selected_series
                else:
                    sample_index = int(selection) - 1
                    selected_sample = sample_names[sample_index]

                # Show the user a choice between single image or image series and get their selection
                print("\nWould you like to choose a single image or an image series? (or 'q' to exit)")
                print("[1] Single Image")
                print("[2] Image Series")
                print("[q] Exit")
                choice = input("Enter the number of your choice: ")
                if choice.lower() == 'q':
                    print("Exiting selection.")
                    return self.selected_series
                choice = int(choice)

                # Get the selected sample's scan list and series list
                scan_list = self.sample_dict[selected_sample]['scanlist']
                series_list = self.sample_dict[selected_sample]['serieslist']

                # Identify series scan IDs and single image scan IDs
                series_scan_ids = set(series_list.keys())
                single_image_scan_ids = [scan_id for scan_id in scan_list if scan_id not in series_scan_ids]

                if choice == 1:
                    # The user has chosen to select a single image
                    print("\nPlease select a scan ID (or 'q' to exit):")
                    for i, scan_id in enumerate(single_image_scan_ids, 1):
                        print(f"[{i}] {scan_id}")
                    print("[q] Exit")
                    selection = input("Enter the number of your choice: ")
                    if selection.lower() == 'q':
                        print("Exiting selection.")
                        return self.selected_series
                    else:
                        scan_id_index = int(selection) - 1
                        selected_scan = single_image_scan_ids[scan_id_index]
                        self.selected_series.append((selected_sample, selected_scan))
                else:
                    # The user has chosen to select an image series
                    print("\nPlease select one or more series (Enter 'a' to select all series, 'q' to finish selection):")
                    selected_series = []
                    while True:
                        for i, series_scan_id in enumerate(series_scan_ids, 1):
                            series_data = series_list[series_scan_id]
                            print(f"[{i}] Series {series_scan_id} (start time: {series_data[0][1]}, exposure time: {series_data[0][2]})")
                        print("[a] All series")
                        print("[q] Finish selection")
                        selection = input("Enter the number(s) of your choice (comma-separated), 'a', or 'q': ")
                        if selection.lower() == 'q':
                            if selected_series:
                                break
                            else:
                                print("Exiting selection.")
                                return self.selected_series
                        elif selection.lower() == 'a':
                            selected_series = list(series_scan_ids)
                            break
                        else:
                            # Get the series indices from the user's input
                            series_indices = list(map(int, selection.split(',')))
                            selected_series += [list(series_scan_ids)[i-1] for i in series_indices]
                    self.selected_series.extend([(selected_sample, series) for series in selected_series])

                print("\nSelection completed.")
            return self.selected_series

# -- Display the RAW TIFF using Matplotlib
    def rawdisplay(self):
        plt.close('all')
        # plt.imshow(self.rawtiff_xr, cmap='jet')
        lb = np.nanpercentile(self.rawtiff_xr, 10)
        ub = np.nanpercentile(self.rawtiff_xr, 99)

        extent = [self.rawtiff_xr['pix_x'].min(), self.rawtiff_xr['pix_x'].max(),
          self.rawtiff_xr['pix_y'].min(), self.rawtiff_xr['pix_y'].max()]
        
        plt.imshow(self.rawtiff_xr, 
                   interpolation='nearest', 
                   cmap='jet',
                   origin='lower', 
                   vmax=ub, 
                   vmin=lb,
                   extent=extent)
        plt.xlabel(self.rawtiff_xr['pix_x'].name)
        plt.ylabel(self.rawtiff_xr['pix_y'].name)
        plt.title('Raw TIFF Image')
        plt.colorbar(label='Intensity')
        plt.show()

# -- Display the Reciprocal Space Map Corrected TIFF using Matplotlib
    def recipdisplay(self):
        plt.close('all')
        lb = np.nanpercentile(self.reciptiff_xr, 10)
        ub = np.nanpercentile(self.reciptiff_xr, 99)

        extent = [self.reciptiff_xr[self.inplane_config].min(), self.reciptiff_xr[self.inplane_config].max(),
                self.reciptiff_xr['q_z'].min(), self.reciptiff_xr['q_z'].max()]

        plt.imshow(self.reciptiff_xr,
                interpolation='nearest',
                cmap='jet',
                origin='lower',
                vmax=ub,
                vmin=lb,
                extent=extent)

        plt.xlabel(self.reciptiff_xr[self.inplane_config].name) # 'q$_{xy}$ (1/$\AA$)'
        plt.ylabel(self.reciptiff_xr['q_z'].name) # 'q$_{z}$ (1/$\AA$)'
        plt.title('Reciprocal Space Corrected Image')
        plt.colorbar(label='Intensity')
        plt.show()

# -- Display the Caked TIFF using Matplotlib
    def cakeddisplay(self):
        plt.close('all')
        # plt.imshow(self.cakedtiff_xr, cmap='jet')
        lb = np.nanpercentile(self.cakedtiff_xr, 10)
        ub = np.nanpercentile(self.cakedtiff_xr, 99)

        extent = [self.cakedtiff_xr['qr'].min(), self.cakedtiff_xr['qr'].max(),
                self.cakedtiff_xr['chi'].min(), self.cakedtiff_xr['chi'].max()]

        plt.imshow(self.cakedtiff_xr,
                interpolation='nearest',
                cmap='jet',
                origin='lower',
                vmax=ub,
                vmin=lb,
                extent=extent)

        plt.xlabel(self.cakedtiff_xr['qr'].name)
        plt.ylabel(self.cakedtiff_xr['chi'].name)
        plt.title('Caked Corrected Image')
        plt.colorbar(label='Intensity')
        plt.show()

'''