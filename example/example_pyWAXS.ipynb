{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pyWAXS\n",
    "#### Python-Based X-ray Scattering Data Reduction Notebook \n",
    "##### Toney Group, Updated: 10/18/2023, Example Notebook\n",
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Start by downloading/installing the 'pyWAXS.yml' virtual environment. Check the README.md or Git page for instructions on installation of this environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install pyWAXS Modules\n",
    "Restart the Kernel after you do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///Users/keithwhite/github_repositories/pyWAXS/main\n",
      "\u001b[31mERROR: file:///Users/keithwhite/github_repositories/pyWAXS/main does not appear to be a Python project: neither 'setup.py' nor 'pyproject.toml' found.\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# !python setup.py clean # uncomment if pip installation fails due to false path\n",
    "%pip install -e /Users/keithwhite/github_repositories/pyWAXS/main # sub your pyWAXS/main directory here.\n",
    "\n",
    "# from IPython.core.display import display, HTML\n",
    "# display(HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")) # Trigger the kernel to restart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                       Version     Editable project location\n",
      "----------------------------- ----------- -------------------------------------------------\n",
      "absl-py                       1.4.0\n",
      "appdirs                       1.4.4\n",
      "appnope                       0.1.3\n",
      "asciitree                     0.3.3\n",
      "ase                           3.22.1\n",
      "asteval                       0.9.29\n",
      "asttokens                     2.2.1\n",
      "astunparse                    1.6.3\n",
      "attrs                         23.1.0\n",
      "backcall                      0.2.0\n",
      "backports.functools-lru-cache 1.6.4\n",
      "blinker                       1.6.2\n",
      "bokeh                         3.1.1\n",
      "cached-property               1.5.2\n",
      "cachetools                    5.3.1\n",
      "certifi                       2023.7.22\n",
      "charset-normalizer            3.1.0\n",
      "click                         8.1.3\n",
      "cloudpickle                   2.2.1\n",
      "comm                          0.1.3\n",
      "contourpy                     1.0.7\n",
      "cvxpy                         1.3.1\n",
      "cycler                        0.11.0\n",
      "Cython                        0.29.34\n",
      "cytoolz                       0.12.0\n",
      "dask                          2023.5.0\n",
      "debugpy                       1.6.7\n",
      "decorator                     5.1.1\n",
      "distributed                   2023.5.0\n",
      "ecos                          2.0.11\n",
      "entrypoints                   0.4\n",
      "et-xmlfile                    1.1.0\n",
      "executing                     1.2.0\n",
      "fabio                         2023.4.1\n",
      "fasteners                     0.17.3\n",
      "fastjsonschema                2.18.0\n",
      "Flask                         3.0.0\n",
      "flatbuffers                   23.5.26\n",
      "fonttools                     4.39.4\n",
      "fsspec                        2023.5.0\n",
      "future                        0.18.3\n",
      "gast                          0.4.0\n",
      "glob2                         0.7\n",
      "Glymur                        0.12.7\n",
      "gmpy2                         2.1.2\n",
      "google-auth                   2.20.0\n",
      "google-auth-oauthlib          1.0.0\n",
      "google-pasta                  0.2.0\n",
      "grpcio                        1.54.2\n",
      "h5netcdf                      1.2.0\n",
      "h5py                          3.8.0\n",
      "hdbscan                       0.8.33\n",
      "hdf5plugin                    4.1.1\n",
      "idna                          3.4\n",
      "imagecodecs                   2023.1.23\n",
      "imageio                       2.31.1\n",
      "importlib-metadata            6.6.0\n",
      "ipykernel                     6.23.1\n",
      "ipympl                        0.9.3\n",
      "ipython                       8.13.2\n",
      "ipython-genutils              0.2.0\n",
      "ipywidgets                    8.0.6\n",
      "itsdangerous                  2.1.2\n",
      "jax                           0.4.12\n",
      "jedi                          0.18.2\n",
      "Jinja2                        3.1.2\n",
      "joblib                        1.3.2\n",
      "jsonschema                    4.19.0\n",
      "jsonschema-specifications     2023.7.1\n",
      "jupyter_client                8.2.0\n",
      "jupyter_core                  5.3.0\n",
      "jupyterlab-widgets            3.0.7\n",
      "keras                         2.12.0\n",
      "kiwisolver                    1.4.4\n",
      "latexcodec                    2.0.1\n",
      "lazy_loader                   0.3\n",
      "libclang                      16.0.0\n",
      "lmfit                         1.2.1\n",
      "locket                        1.0.0\n",
      "lxml                          4.9.2\n",
      "lz4                           4.3.2\n",
      "Mako                          1.2.4\n",
      "Markdown                      3.4.3\n",
      "MarkupSafe                    2.1.2\n",
      "matplotlib                    3.7.1\n",
      "matplotlib-inline             0.1.6\n",
      "ml-dtypes                     0.2.0\n",
      "monty                         2023.9.25\n",
      "mpmath                        1.3.0\n",
      "msgpack                       1.0.5\n",
      "munkres                       1.1.4\n",
      "nbformat                      5.9.2\n",
      "nest-asyncio                  1.5.6\n",
      "networkx                      3.1\n",
      "numcodecs                     0.11.0\n",
      "numexpr                       2.8.4\n",
      "numpy                         1.25.0\n",
      "oauthlib                      3.2.2\n",
      "opencv-contrib-python         4.8.1.78\n",
      "opencv-python                 4.7.0\n",
      "openpyxl                      3.1.2\n",
      "opt-einsum                    3.3.0\n",
      "ordered-set                   4.1.0\n",
      "osqp                          0.6.3\n",
      "packaging                     23.1\n",
      "palettable                    3.3.3\n",
      "pandas                        2.0.3\n",
      "parso                         0.8.3\n",
      "partd                         1.4.0\n",
      "pexpect                       4.8.0\n",
      "pickleshare                   0.7.5\n",
      "Pillow                        9.4.0\n",
      "pip                           23.1.2\n",
      "platformdirs                  3.5.1\n",
      "plotly                        5.15.0\n",
      "ply                           3.11\n",
      "pooch                         1.7.0\n",
      "prompt-toolkit                3.0.38\n",
      "protobuf                      4.23.3\n",
      "psutil                        5.9.5\n",
      "ptyprocess                    0.7.0\n",
      "pure-eval                     0.2.2\n",
      "pyarrow                       7.0.1\n",
      "pyasn1                        0.5.0\n",
      "pyasn1-modules                0.3.0\n",
      "pybtex                        0.24.0\n",
      "pyFAI                         2023.5.0\n",
      "pygix                         2022.11.14\n",
      "Pygments                      2.15.1\n",
      "PyLaTeX                       1.4.1\n",
      "pymatgen                      2023.10.4\n",
      "pyopencl                      2023.1\n",
      "pyparsing                     3.0.9\n",
      "PyQt5                         5.15.7\n",
      "PyQt5-sip                     12.11.0\n",
      "pyqtgraph                     0.13.3\n",
      "PySocks                       1.7.1\n",
      "python-dateutil               2.8.2\n",
      "pytools                       2022.1.14\n",
      "pytz                          2023.3\n",
      "PyWavelets                    1.4.1\n",
      "pyWAXS                        0.2.0       /Users/keithwhite/github_repositories/pyWAXS/main\n",
      "PyYAML                        6.0\n",
      "pyzmq                         25.0.2\n",
      "qdldl                         0.1.5.post2\n",
      "qtconsole                     5.4.3\n",
      "QtPy                          2.3.1\n",
      "referencing                   0.30.2\n",
      "requests                      2.31.0\n",
      "requests-oauthlib             1.3.1\n",
      "rpds-py                       0.9.2\n",
      "rsa                           4.9\n",
      "ruamel.yaml                   0.17.35\n",
      "ruamel.yaml.clib              0.2.8\n",
      "scikit-image                  0.21.0\n",
      "scikit-learn                  1.3.0\n",
      "scipy                         1.10.1\n",
      "scs                           3.2.3\n",
      "seaborn                       0.13.0\n",
      "setuptools                    59.8.0\n",
      "setuptools-scm                7.1.0\n",
      "silx                          1.1.2\n",
      "sip                           6.7.9\n",
      "six                           1.16.0\n",
      "sortedcontainers              2.4.0\n",
      "spglib                        2.0.2\n",
      "stack-data                    0.6.2\n",
      "sympy                         1.12\n",
      "tabulate                      0.9.0\n",
      "tblib                         1.7.0\n",
      "tenacity                      8.2.2\n",
      "tensorboard                   2.12.3\n",
      "tensorboard-data-server       0.7.1\n",
      "tensorflow-estimator          2.12.0\n",
      "tensorflow-io-gcs-filesystem  0.32.0\n",
      "termcolor                     2.3.0\n",
      "threadpoolctl                 3.2.0\n",
      "tifffile                      2023.8.12\n",
      "tk                            0.1.0\n",
      "toml                          0.10.2\n",
      "tomli                         2.0.1\n",
      "toolz                         0.12.0\n",
      "tornado                       6.3.2\n",
      "tqdm                          4.66.1\n",
      "traitlets                     5.9.0\n",
      "typing_extensions             4.6.0\n",
      "tzdata                        2023.3\n",
      "uncertainties                 3.1.7\n",
      "urllib3                       1.26.16\n",
      "wcwidth                       0.2.6\n",
      "Werkzeug                      2.3.6\n",
      "wheel                         0.40.0\n",
      "widgetsnbextension            4.0.7\n",
      "wrapt                         1.14.1\n",
      "xarray                        2023.6.0\n",
      "XlsxWriter                    3.1.2\n",
      "xyzservices                   2023.5.0\n",
      "zarr                          2.16.1\n",
      "zict                          3.0.0\n",
      "zipp                          3.15.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/opt/anaconda3/envs/pyGIXS/bin/python'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import importlib.util\n",
    "# spec = importlib.util.find_spec(\"pyWAXS\")\n",
    "# print(spec)\n",
    "\n",
    "!pip list\n",
    "\n",
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class & Module Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/keithwhite/github_repositories/pyWAXS/example', '/opt/anaconda3/envs/pyGIXS/lib/python311.zip', '/opt/anaconda3/envs/pyGIXS/lib/python3.11', '/opt/anaconda3/envs/pyGIXS/lib/python3.11/lib-dynload', '', '/opt/anaconda3/envs/pyGIXS/lib/python3.11/site-packages', '/Users/keithwhite/github_repositories/pyWAXS/main']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyWAXS'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/keithwhite/github_repositories/pyWAXS/example/example_pyWAXS.ipynb Cell 7\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/keithwhite/github_repositories/pyWAXS/example/example_pyWAXS.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mimportlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/keithwhite/github_repositories/pyWAXS/example/example_pyWAXS.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpyWAXS\u001b[39;00m \u001b[39m# type: ignore\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/keithwhite/github_repositories/pyWAXS/example/example_pyWAXS.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpyWAXS\u001b[39;00m \u001b[39mimport\u001b[39;00m WAXSFileManager, WAXSReduce, WAXSSearch, WAXSTransform \u001b[39m# type: ignore\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/keithwhite/github_repositories/pyWAXS/example/example_pyWAXS.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# from pyWAXS.main import MoleculeConstructor, pyWAXS, pyWAXSim, WAXSAFF, WAXSAnalyze, WAXSComputeCrystal, WAXSDiffSim, WAXSExperiment, WAXSFileManager, WAXSReduce, WAXSReverse, WAXSSearch, WAXSTransform, WAXSVisualizer\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/keithwhite/github_repositories/pyWAXS/example/example_pyWAXS.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/keithwhite/github_repositories/pyWAXS/example/example_pyWAXS.ipynb#W6sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# Import other modules you will use inline within the notebook.\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyWAXS'"
     ]
    }
   ],
   "source": [
    "import importlib.util\n",
    "import pyWAXS # type: ignore\n",
    "from pyWAXS import WAXSFileManager, WAXSReduce, WAXSSearch, WAXSTransform # type: ignore\n",
    "# from pyWAXS.main import MoleculeConstructor, pyWAXS, pyWAXSim, WAXSAFF, WAXSAnalyze, WAXSComputeCrystal, WAXSDiffSim, WAXSExperiment, WAXSFileManager, WAXSReduce, WAXSReverse, WAXSSearch, WAXSTransform, WAXSVisualizer\n",
    "\n",
    "# Import other modules you will use inline within the notebook.\n",
    "import xarray as xr # type: ignore\n",
    "import pandas as pd # type: ignore\n",
    "import numpy as np\n",
    "import pathlib, os\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "spec = importlib.util.find_spec(\"pyWAXS\")\n",
    "print(spec)\n",
    "\n",
    "# whos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a pyWAXS Project\n",
    "Specify a 'project_name', if you already have a project with this name, the 'generate_projectPaths' method will just load those filepaths locally so you can access them. \n",
    "\n",
    "If you don't have a folder with the project_name, it will be automatically created for you, along with all of the subdirectories that come along with it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = 'LaB6_SRM660c_Calib' # Change this for each sample.\n",
    "\n",
    "# Initialize variables\n",
    "basePath = Path('/Users/keithwhite/github_repositories/pyWAXS/example')\n",
    "\n",
    "# Generate project paths\n",
    "projectPath, PathList = waxsfiles.generate_projectPaths(basePath, project_name)\n",
    "\n",
    "# Print results\n",
    "print(f\"Project Path: {projectPath}\")\n",
    "print(f\"List of All Paths: {PathList}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Metadata Keylist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_keylist = ['sample', # Sample Number\n",
    "                    'saxssdd', # Sample Chemistry\n",
    "                    'energy', # Solution Filtration\n",
    "                    'note', # Solution Concentration\n",
    "                    'clocktime', # Clock time @ Endstation\n",
    "                    'xpos', # X-Position of Beam\n",
    "                    'thpos', # Incidence Angle\n",
    "                    'exptime', # Exposure Time\n",
    "                    'scanID', # Scan Identification Number (BNL Specific)\n",
    "                    'detext'] # Extension of the detector identifier at BNL 'maxs' v. 'saxs' v, 'waxs'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a WAXSReduce Project Instance Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - WAXSReduce Class Instantiation: Load the data, apply mask, calculate and map q-range, Ewald sphere corrections/pixel splitting, and caked pixel splitting.\n",
    "waxs_analysis = WAXSReduce(poniPath=poniPath, \n",
    "        maskPath=maskPath, \n",
    "        tiffPath=dataPath, \n",
    "        metadata_keylist=metadata_keylist,\n",
    "        energy = 12.7)\n",
    "\n",
    "# integrator = Integration1D(waxs_analysis) # Create the 1D integrator session.\n",
    "\n",
    "methods = 'np', 'cython', 'bbox', 'splitpix', 'lut'\n",
    "# Run the 1D integration using the run_pg_integrate1D method.\n",
    "waxs_analysis.run_pg_integrate1D(npt=1024, \n",
    "                                 method='bbox', # \n",
    "                                 correctSolidAngle=True, \n",
    "                                 polarization_factor=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate a .xye File for TOPAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a WAXSTOPAS instance based on the existing WAXSReduce instance\n",
    "waxs_topas = WAXSTOPAS(projectPath=projectPath, waxs_instance=waxs_analysis)\n",
    "\n",
    "# Now you can call the .xye generation method\n",
    "waxs_topas.generate_xye_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the Stored WAXSReduce DataArrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "title = projectname\n",
    "\n",
    "waxs_analysis.display_image(waxs_analysis.cakedtiff_xr, \n",
    "                            title=title, \n",
    "                            cmap='turbo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generalized Analysis Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sin(chi) Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caked Image Sin-Chi Correction: Apply sin(chi) correction to the caked image.\n",
    "cakedtiff_sinchi_xr = waxs_analysis.sinchi_corr(chicorr = True, \n",
    "                                                qsqr = False)\n",
    "\n",
    "# Image Normalization: Normalize the caked image.\n",
    "cakedtiff_xr_norm, (max_x, max_y) = waxs_analysis.normalize_image(img = waxs_analysis.cakedtiff_sinchi_xr, \n",
    "                                                  normalizerecip=False)\n",
    "data = cakedtiff_xr_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image Folding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Folding: Fold the caked image.\n",
    "folded_data = waxs_analysis.fold_image(data, 'chi')\n",
    "data = folded_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = waxs_analysis.cakedtiff_xr\n",
    "\n",
    "# Image Normalization: Normalize the caked image.\n",
    "data, (max_x, max_y) = waxs_analysis.normalize_image(img = data, \n",
    "                                                  normalizerecip=False)\n",
    "\n",
    "# Image Interpolation: Interpolate the folded image.\n",
    "# interpolator = ImageInterpolator() # Create the interpolator object. \n",
    "# data = interpolator.simple_interpolate(data, 'horizontal', 'slinear') # interpolate horizontal gaps with slinear method.\n",
    "# data = interpolator.simple_interpolate(data, 'vertical', 'slinear') # interpolate unfilled vertical gaps with slinear method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Folding: Fold the caked image.\n",
    "data = waxs_analysis.cakedtiff_xr\n",
    "data = waxs_analysis.fold_image(data, 'chi')\n",
    "data, (max_x, max_y) = waxs_analysis.normalize_image(img = data, \n",
    "                                                  normalizerecip=False)\n",
    "\n",
    "# Display Image\n",
    "waxs_analysis.display_image(data, \n",
    "                            title='folded', \n",
    "                            cmap='turbo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Peak Finding\n",
    "Find the peaks using a our custom peak finding algorithm.\n",
    "\n",
    "Parameters:\n",
    "- sigma1 (float, default=1.0): The standard deviation for the first Gaussian filter.\n",
    "- sigma2 (float, default=2.0): The standard deviation for the second Gaussian filter.\n",
    "- threshold (float, default=0.2): Threshold for initial peak identification.\n",
    "- clustering_method (str, default='DBSCAN'): The clustering method to use ('DBSCAN' or 'HDBSCAN').\n",
    "- eps (float, default=3): The maximum distance between two samples for them to be considered as in the same cluster (DBSCAN).\n",
    "- min_samples (int, default=2): The number of samples in a neighborhood for a point to be considered as a core point (DBSCAN).\n",
    "- k (int, default=3): The number of nearest neighbors to consider for the recentering algorithm.\n",
    "- radius (float, default=5): The radius within which to search for neighbors in the recentering algorithm.\n",
    "- edge_percentage (float, default=5): The percentage of the minimum edge length to be considered as the edge zone.\n",
    "- stricter_threshold (float, default=0.01): A stricter threshold for edge peaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "%matplotlib widget\n",
    "\n",
    "# Find peaks (implement the actual peak-finding logic in the find_peaks method)\n",
    "peak_finder = WAXSSearch(data) # create the WAXSSearch object\n",
    "\n",
    "# NOTE: Make sure you pass the ACTIVE DataArray you are working on, notice how I passed 'data' \n",
    "# since this is the processed dataset we are working with locally.\n",
    "\n",
    "dataset = peak_finder.waxssearch_main(sigma1=.1,\n",
    "                                  sigma2=1.5,\n",
    "                                  threshold=.015,\n",
    "                                  clustering_method='HDBSCAN',\n",
    "                                  eps=1, \n",
    "                                  min_samples=2,\n",
    "                                  k=8,\n",
    "                                  radius=10,\n",
    "                                  edge_percentage=2,\n",
    "                                  stricter_threshold=20)\n",
    "\n",
    "# Display image with peaks\n",
    "peak_finder.display_image_with_peaks_and_DoG(dataset,\n",
    "                                       title='peak finder', \n",
    "                                       cmap='turbo')\n",
    "\n",
    "# peak_finder.save_to_netcdf(hdf5Path) # Creates an hdf5 file with the name 'output.nc' in your output path. Will generalize\n",
    "# the file naming convention for this soon.\n",
    "'''\n",
    "\n",
    "%matplotlib widget\n",
    "\n",
    "data = waxs_analysis.reciptiff_xr\n",
    "# data = waxs_analysis.fold_image(data, 'chi')\n",
    "# data, (max_x, max_y) = waxs_analysis.normalize_image(img = data, \n",
    "#                                                   normalizerecip=False)\n",
    "\n",
    "# Find peaks (implement the actual peak-finding logic in the find_peaks method)\n",
    "peak_finder = WAXSSearch(data) # create the WAXSSearch object\n",
    "\n",
    "# NOTE: Make sure you pass the ACTIVE DataArray you are working on, notice how I passed 'data' \n",
    "# since this is the processed dataset we are working with locally.\n",
    "\n",
    "const_params = {\n",
    "    'threshold': 0.0005,\n",
    "    'clustering_method': 'HDBSCAN',\n",
    "    'eps': 1,\n",
    "    'min_samples': 2,\n",
    "    'k': 4,\n",
    "    'radius': 2,\n",
    "    'edge_percentage': 2,\n",
    "    'stricter_threshold': 20\n",
    "}\n",
    "\n",
    "dataset = peak_finder.waxssearch_main(sigma1=.15,\n",
    "                                        sigma2=2.91,\n",
    "                                        **const_params)\n",
    "\n",
    "# Display image with peaks\n",
    "peak_finder.display_image_with_peaks_and_DoG(dataset,\n",
    "                                       title='peak finder', \n",
    "                                       cmap='turbo')\n",
    "\n",
    "# peak_finder.save_to_netcdf(hdf5Path) # Creates an hdf5 file with the name 'output.nc' in your output path. Will generalize\n",
    "# the file naming convention for this soon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Peak Search Parameter Sensitivity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Peak Search Parameter Sensitivity Analysis\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Import the WAXSSearch class and any other dependencies here\n",
    "\n",
    "# Define constant parameters\n",
    "const_params = {\n",
    "    'threshold': 0.0005,\n",
    "    'clustering_method': 'HDBSCAN',\n",
    "    'eps': 1,\n",
    "    'min_samples': 2,\n",
    "    'k': 4,\n",
    "    'radius': 2,\n",
    "    'edge_percentage': 2,\n",
    "    'stricter_threshold': 5\n",
    "}\n",
    "\n",
    "# Assume that 'data' is available here or load it\n",
    "\n",
    "# Define ranges for sigma1 and sigma2\n",
    "sigma1_values = np.linspace(0.1, 1.2, 20)\n",
    "sigma2_values = np.linspace(1.3, 3, 20)\n",
    "\n",
    "# Create a matrix to store the results\n",
    "num_peaks_matrix = np.zeros((len(sigma1_values), len(sigma2_values)))\n",
    "\n",
    "# Run the simulation\n",
    "for i, sigma1 in enumerate(sigma1_values):\n",
    "    for j, sigma2 in enumerate(sigma2_values):\n",
    "        # Create a WAXSSearch object with the current 'data'\n",
    "        peak_finder = WAXSSearch(data)\n",
    "        \n",
    "        # Run the actual waxssearch_main method\n",
    "        dataset = peak_finder.waxssearch_main(sigma1=sigma1,\n",
    "                                              sigma2=sigma2,\n",
    "                                              **const_params)\n",
    "        \n",
    "        # Extract the number of peaks found\n",
    "        num_peaks = np.count_nonzero(dataset['peak_positions'].values == 1)\n",
    "        num_peaks_matrix[i, j] = num_peaks\n",
    "\n",
    "\n",
    "# Convert to DataFrame for better annotation in heatmap\n",
    "df_num_peaks = pd.DataFrame(num_peaks_matrix, index=np.round(sigma1_values, 2), columns=np.round(sigma2_values, 2))\n",
    "\n",
    "plt.close('all')\n",
    "\n",
    "# Generate the heatmap\n",
    "sns.heatmap(df_num_peaks, annot=True, fmt=\".0f\", cmap=\"YlGnBu\")\n",
    "plt.xlabel(\"Sigma2 Values\")\n",
    "plt.ylabel(\"Sigma1 Values\")\n",
    "plt.title(\"Heatmap of Number of Peaks Detected\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio  # for creating GIF\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Import WAXSSearch and other dependencies here\n",
    "# ...\n",
    "\n",
    "# Assume that 'data' is available here or load it\n",
    "# ...\n",
    "\n",
    "# Define constant parameters\n",
    "const_params = {\n",
    "    'clustering_method': 'HDBSCAN',\n",
    "    'eps': 1,\n",
    "    'min_samples': 2,\n",
    "    'k': 4,\n",
    "    'radius': 2,\n",
    "    'edge_percentage': 2,\n",
    "    'stricter_threshold': 5\n",
    "}\n",
    "\n",
    "# Define ranges for sigma1, sigma2, and threshold\n",
    "sigma1_values = np.linspace(0.1, 1.2, 20)\n",
    "sigma2_values = np.linspace(1.3, 3, 20)\n",
    "threshold_values = np.linspace(0.0001, 0.001, 10)  # Replace with your range\n",
    "\n",
    "# Initialize a list to store heatmap frames\n",
    "frames = []\n",
    "\n",
    "# Loop over different threshold values\n",
    "for t, threshold in enumerate(threshold_values):\n",
    "    num_peaks_matrix = np.zeros((len(sigma1_values), len(sigma2_values)))\n",
    "\n",
    "    for i, sigma1 in enumerate(sigma1_values):\n",
    "        for j, sigma2 in enumerate(sigma2_values):\n",
    "            if sigma1 >= sigma2:\n",
    "                continue\n",
    "\n",
    "            peak_finder = WAXSSearch(data)\n",
    "            dataset = peak_finder.waxssearch_main(sigma1=sigma1, sigma2=sigma2, threshold=threshold, **const_params)\n",
    "            num_peaks = np.count_nonzero(dataset['peak_positions'].values == 1)\n",
    "            num_peaks_matrix[i, j] = num_peaks\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df_num_peaks = pd.DataFrame(num_peaks_matrix, index=np.round(sigma1_values, 2), columns=np.round(sigma2_values, 2))\n",
    "    \n",
    "    # Generate and save the heatmap\n",
    "    plt.figure()\n",
    "    sns.heatmap(df_num_peaks, annot=True, fmt=\".0f\", cmap=\"YlGnBu\")\n",
    "    plt.xlabel(\"Sigma2 Values\")\n",
    "    plt.ylabel(\"Sigma1 Values\")\n",
    "    plt.title(f\"Heatmap of Number of Peaks Detected (Threshold={threshold})\")\n",
    "    \n",
    "    # Save as PNG\n",
    "    plt.savefig(f\"heatmap_{t}.png\")\n",
    "    \n",
    "    # Append to frames for GIF\n",
    "    frames.append(imageio.imread(f\"heatmap_{t}.png\"))\n",
    "\n",
    "# Create GIF\n",
    "imageio.mimsave('heatmap.gif', frames, duration=1)  # 1-second duration for each frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Existing Project File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# waxsPath = pathlib.Path('/Users/keithwhite/github_repositories/pyWAXS/examples_local/projects/1MAI_3PbI2_DMF_1M_mar23/analysis/hdf5/3MAI_1PbI2_DMF_1M_mar23_peaks.nc')\n",
    "waxsPath = pathlib.Path('/Users/keithwhite/github_repositories/pyWAXS/examples_local/projects/1MAI_3PbI2_DMF_1M_mar23/analysis/hdf5/output.nc')\n",
    "\n",
    "waxs_ds = waxs_analysis.load_xarray_dataset(waxsPath)\n",
    "\n",
    "waxs_ds.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waxs_ds_peaks = WAXSSearch(waxs_ds) # create the WAXSSearch object\n",
    "\n",
    "# Display image with peaks\n",
    "waxs_ds_peaks.display_image_with_peaks(waxs_analysis.ds,\n",
    "                                       title='manual peaks', \n",
    "                                       cmap='turbo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1D Integration Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "integrator = Integration1D(waxs_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now your integrator object 'integrator' has access to and references your active 'waxs_analysis' session. \n",
    "\n",
    "It also has access to all of the WAXSReduce() methods. You can prove it to yourself like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) Cake Slide 1D: Display 2D Caked Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "integrator.display_image(integrator.cakedtiff_xr, # Display the caked data we will manipulate with the 1D image processing.\n",
    "                            title='processed', \n",
    "                            cmap='turbo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) Cake Slice 1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "integrator = Integration1D(waxs_analysis)\n",
    "\n",
    "integrator.cakeslice1D(integrator.cakedtiff_xr, chislice=[-90, 90], qrslice=[0, 4], cakeslicesum='chi')\n",
    "\n",
    "integrator.display_image1D(integrator.cakeslice1D_xr, color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) Boxcut 1D: Display 2D Recip Space Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "# integrator = Integration1D(waxs_analysis)\n",
    "integrator.display_image(integrator.reciptiff_xr, # Display the caked data we will manipulate with the 1D image processing.\n",
    "                            title='recip space map', \n",
    "                            cmap='turbo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) Box Cut 1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated `process_slices` function to dynamically generate a sample name prefix based on the slices\n",
    "def process_slices(integrator, base_samplenameprefix, pngPath, plot_interpolated=False, interpolate_gaps = False, interp_method = 'linear', order = None):\n",
    "    # Qz Layer Lines\n",
    "    qxyslice_qz = [-2.5, 2.5]\n",
    "    qzslice_qz_list = [\n",
    "        [.42, .57],\n",
    "        [.9, 1.07],\n",
    "        [1.42, 1.58],\n",
    "        [1.83, 2.16],\n",
    "        [2.4, 2.6]\n",
    "    ]\n",
    "    \n",
    "    for qzslice in qzslice_qz_list:\n",
    "        dynamic_samplenameprefix = f\"{base_samplenameprefix}_qxyrange{qxyslice_qz[0]}_{qxyslice_qz[1]}_qzrange{qzslice[0]}_{qzslice[1]}\"\n",
    "        title = generate_title('qz', qxyslice_qz, qzslice)\n",
    "        integrator.boxcut1D(integrator.reciptiff_xr, qxyslice=qxyslice_qz, qzslice=qzslice, boxcutsum='qz', interpolate_gaps=interpolate_gaps, interp_method = interp_method, order = None)\n",
    "        integrator.display_image1D(integrator, color='blue', title=title, save_image=True, samplenameprefix=dynamic_samplenameprefix, savePath=pngPath, plot_interpolated=plot_interpolated)\n",
    "        \n",
    "    # Qxy Layer Lines\n",
    "    qzslice_qxy = [0, 3]\n",
    "    qxyslice_qxy_list = [\n",
    "        [-0.95, -0.7],\n",
    "        [-1.18, -1.08],\n",
    "        [-1.7, -1.45],\n",
    "        [-2.06, -1.9],\n",
    "        [-2.24, -2.1],\n",
    "        [-2.36, -2.26]\n",
    "    ]\n",
    "    \n",
    "    for qxyslice in qxyslice_qxy_list:\n",
    "        dynamic_samplenameprefix = f\"{base_samplenameprefix}_qxyrange{qxyslice[0]}_{qxyslice[1]}_qzrange{qzslice_qxy[0]}_{qzslice_qxy[1]}\"\n",
    "        title = generate_title('qxy', qxyslice, qzslice_qxy)\n",
    "        integrator.boxcut1D(integrator.reciptiff_xr, qxyslice=qxyslice, qzslice=qzslice_qxy, boxcutsum='qxy', interpolate_gaps=interpolate_gaps, interp_method = interp_method)\n",
    "        integrator.display_image1D(integrator, color='red', title=title, save_image=True, samplenameprefix=dynamic_samplenameprefix, savePath=pngPath, plot_interpolated=plot_interpolated)\n",
    "        \n",
    "# The generate_title function for reference\n",
    "def generate_title(boxcutsum, qxyslice=None, qzslice=None):\n",
    "    if boxcutsum == 'qz':\n",
    "        title = f\"Qz Layer Lines (Qxy: {qzslice[0]} to {qzslice[1]})\"\n",
    "    elif boxcutsum == 'qxy':\n",
    "        title = f\"Qxy Layer Lines (Qz: {qxyslice[0]} to {qxyslice[1]})\"\n",
    "    return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_samplenameprefix = '3MAI1PbI2_DMF_1M'\n",
    "# interp_method = 'cubic', 'slinear', 'nearest', 'zero', 'linear'\n",
    "interp_method = 'linear'\n",
    "process_slices(integrator, base_samplenameprefix, pngPath, plot_interpolated=False, interpolate_gaps = False, interp_method = 'linear', order = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) Pole Figure 1D: Display 2D Caked Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "integrator.display_image(integrator.cakedtiff_xr, # Display the caked data we will manipulate with the 1D image processing.\n",
    "                            title='processed', \n",
    "                            cmap='turbo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) Pole Figure 1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# integrator.polefig1D(integrator.cakedtiff_xr, pole_chislice=[-90, 90], pole_qrslice=[1.8, 1.92], qrcenter=1.85, chicenter=0, poleleveler='linear')\n",
    "integrator.polefig1D(integrator.cakedtiff_xr, pole_chislice=[-90, 90], pole_qrslice=[.62, .75], qrcenter=.67, chicenter=0, poleleveler='average')\n",
    "# integrator.polefig1D(integrator.cakedtiff_xr, pole_chislice=[-90, 90], pole_qrslice=[.62, .75], qrcenter=.67, chicenter=0, poleleveler=None)\n",
    "# integrator.polefig1D(integrator.cakedtiff_xr, pole_chislice=[-90, 90], pole_qrslice=[.62, .75], qrcenter=.67, chicenter=0, poleleveler='linear')\n",
    "\n",
    "integrator.display_image1D(integrator.polefig1D_xr, color='blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (4) Azimuthal Integration: Display the 2D Recip Space Map\n",
    "This is effectively the same as the caked integration, but with our own custom pixel splitting routine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "integrator.display_image(integrator.reciptiff_xr, # Display the caked data we will manipulate with the 1D image processing.\n",
    "                            title='recip space map', \n",
    "                            cmap='turbo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) Setup DataPaths & Metadata Keys Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Base Path Definitions -- #\n",
    "basePath = pathlib.Path('/Users/keithwhite/github_repositories/pyWAXS/example')\n",
    "dataPath = basePath.joinpath('data') # Generalized path for data.\n",
    "poniPath = basePath.joinpath('poni') # PONI (.poni) File\n",
    "maskPath = basePath.joinpath('mask') # MASK (.edf, .json)\n",
    "outputPath = basePath.joinpath('output') # Generalized for file outputs\n",
    "\n",
    "# -- Example Specific Paths -- #\n",
    "# TIFF File w/ Data\n",
    "tiffPath = dataPath.joinpath('sam22_1MAI1PbI2_unfilt_0p3M_5p0scfh_Si_30uL_043_2068.2s_x0.015_th0.300_0.49s_986546_001639_maxs.tiff')\n",
    "# PONI File Calibrant\n",
    "poniPath = poniPath.joinpath('may23_poni4_nslsiimar23_12p7keV_CeO_KWPos_mask5_fit2.poni')\n",
    "# Image Mask File\n",
    "maskPath = maskPath.joinpath('may23_nslsiimar23_12p7keV_AgBh_KWPos_wSi_th0p3_mask_5.edf')\n",
    "# Output for HDF5 File Format (a nicely formatted output file we will use)\n",
    "hdf5Path = outputPath.joinpath('hdf5') # output path for generated hdf5 files\n",
    "\n",
    "# -- TIFF Path & Corresponding Metadata Keylist -- #\n",
    "# Look at your filename, each '_' delimiter spaces out two keys. Add one key for each position in the filename.\n",
    "metadata_keylist = ['samplenum', # Sample Number\n",
    "                    'chemistry', # Sample Chemistry\n",
    "                    'filter', # Solution Filtration\n",
    "                    'concentration', # Solution Concentration\n",
    "                    'purge_rate', # Spincoater Purge Rate\n",
    "                    'substrate', # Sample Substrate\n",
    "                    'solution_volume', # Dispensed Volume\n",
    "                    'runnum', # Run Number @ Beamtime Session\n",
    "                    'clocktime', # Clock time @ Endstation\n",
    "                    'xpos', # X-Position of Beam\n",
    "                    'thpos', # Incidence Angle\n",
    "                    'exptime', # Exposure Time\n",
    "                    'scanID', # Scan Identification Number (BNL Specific)\n",
    "                    'framenum', # Frame number for tr-GIWAXS series exposures (in-situ time series)\n",
    "                    'detext'] # Extension of the detector identifier at BNL 'maxs' v. 'saxs' v, 'waxs'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Create Project Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - WAXSReduce Class Instantiation\n",
    "waxs_analysis = WAXSReduce(poniPath=poniPath, \n",
    "        maskPath=maskPath, \n",
    "        tiffPath=tiffPath, \n",
    "        metadata_keylist=metadata_keylist,\n",
    "        energy = 12.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Notice how we loaded all of the following: image correction file references, the X-ray energy, and the data?\n",
    "\n",
    "Assuming your file has the incidence angle in the sample name, we can generate accurately corrected images. You can now access the reciprocal space image corrections and caked image corrections:\n",
    "\n",
    "Reciprocal Space Map:\n",
    "```python\n",
    "waxs_analysis.reciptiff_xr\n",
    "```\n",
    "\n",
    "Caked Image:\n",
    "```python\n",
    "waxs_analysis.cakedtiff_xr\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waxs_analysis.reciptiff_xr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Note how we had to use the syntax:\n",
    "```python\n",
    "waxs_analysis.\n",
    "```\n",
    "##### to access the the data.\n",
    "This is how we access the instance that refers to your analysis project. You can have multiple instances coexist in the same notebook.\n",
    "\n",
    "Now, click the 'Attributes' dropdown above. We loaded the data into an XArray DataArray (DA). \n",
    "##### All of the keys listed above in the setup were used to extract your metadata from the filename."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Image Plotting Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) Display Image (Generalized Plotting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "# -- Display the Caked Image\n",
    "# waxs_analysis.cakeddisplay_xr() # method 1\n",
    "\n",
    "# waxs_analysis.display_image(waxs_analysis.cakedtiff_xr, # method 2\n",
    "waxs_analysis.display_image(waxs_analysis.cakedtiff_xr, \n",
    "                            title='caked image', \n",
    "                            cmap='turbo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### You can plot the data stored as attributes with one of a set of built-in methods, or a generalized method.\n",
    "\n",
    "Custom Method (Caked Image):\n",
    "```python\n",
    "waxs_analysis.cakeddisplay_xr()\n",
    "```\n",
    "General Method Equivalent:\n",
    "```python\n",
    "waxs_analysis.display_image(waxs_analysis.cakedtiff_xr, \n",
    "                            title='Caked Image', \n",
    "                            cmap='turbo')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Quick Plotting Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (i) Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "waxs_analysis.rawdisplay_xr()\n",
    "# waxs_analysis.rawtiff_xr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (ii) Reciprocal Space Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "waxs_analysis.recipdisplay_xr()\n",
    "# waxs_analysis.reciptiff_xr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (iii) Caked Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "waxs_analysis.cakeddisplay_xr()\n",
    "# waxs_analysis.cakedtiff_xr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) 2D Image Processing Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) Image Intensity Correction (sin(chi)) Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "cakedtiff_sinchi_xr = waxs_analysis.sinchi_corr(chicorr = True, \n",
    "                                                qsqr = False)\n",
    "\n",
    "waxs_analysis.display_image(waxs_analysis.cakedtiff_sinchi_xr, \n",
    "                            title='caked image, sin(chi) corrected', \n",
    "                            cmap='turbo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Image Normalization Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "# Generate the normalized reciprocal space map image\n",
    "cakedtiff_xr_norm, (max_x, max_y) = waxs_analysis.normalize_image(img = waxs_analysis.cakedtiff_sinchi_xr, \n",
    "                                                  normalizerecip=False)\n",
    "\n",
    "# Check if the returned image is None or not of a compatible type\n",
    "if cakedtiff_xr_norm is None or not isinstance(cakedtiff_xr_norm, (np.ndarray, xr.DataArray)):\n",
    "    raise ValueError(\"The normalized image is None or not of a compatible type.\")\n",
    "\n",
    "print ('Maximum Intensity Pixel Coordinate: ', 'x: ', max_x, 'y: ', max_y)\n",
    "\n",
    "# Display the normalized image\n",
    "waxs_analysis.display_image(cakedtiff_xr_norm, \n",
    "                            title='caked, sin(chi) corrected, normalized', \n",
    "                            cmap='turbo')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c) Image Folding Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a WAXS_Analyze instance and test the fold_image method\n",
    "# waxs = WAXS_Analyze()\n",
    "# original_data = .cakedtiff_xr.copy()\n",
    "# folded_data = waxs.fold_image(waxs.cakedtiff_xr, 'chi')\n",
    "\n",
    "original_data = cakedtiff_xr_norm\n",
    "# original_data = waxs_analysis.cakedtiff_xr\n",
    "folded_data = waxs_analysis.fold_image(original_data, 'chi')\n",
    "\n",
    "# Display the original and folded data for validation\n",
    "# original_data, folded_data\n",
    "\n",
    "waxs_analysis.display_image(folded_data, \n",
    "                            title='caked, sin(chi) corrected, normalized, folded', \n",
    "                            cmap='turbo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (d) Image Interpolation Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib widget\n",
    "\n",
    "data = folded_data\n",
    "\n",
    "interpolator = ImageInterpolator()\n",
    "data = interpolator.simple_interpolate(data, 'horizontal', 'slinear')\n",
    "data = interpolator.simple_interpolate(data, 'vertical', 'slinear')\n",
    "# data = interpolator.patch_interpolate(data)\n",
    "\n",
    "# interpolator.save_dataarray_to_netcdf(interpolated_img, 'test_file')\n",
    "\n",
    "waxs_analysis.display_image(data, \n",
    "                            title='interpolated', \n",
    "                            cmap='turbo')\n",
    "\n",
    "''' # -- Testing Different Interpolation Algorithms\n",
    "# interpolated_img = interpolator.patch_interpolate(data)\n",
    "# interp_horizontal = interpolator.linear_interpolate(data, 'horizontal')\n",
    "# interp_vertical = interpolator.linear_interpolate(data, 'vertical')\n",
    "# interpolated = interpolator.simple_interpolate(data, 'vertical', 'linear')\n",
    "\n",
    "# # Create an instance of the ImageInterpolator class\n",
    "# interpolator = ImageInterpolator()\n",
    "\n",
    "# # Define methods and directions\n",
    "# # methods = [\"linear\", \"nearest\", \"zero\", \"slinear\", \"quadratic\", \"cubic\",\n",
    "# #            \"polynomial\", \"barycentric\", \"krog\", \"pchip\", \"spline\", \"akima\"]\n",
    "# methods = [\"linear\", \"nearest\", \"zero\", \"slinear\", \"akima\"]\n",
    "# directions = [\"vertical\", \"horizontal\"]\n",
    "\n",
    "# # Let's visualize all the interpolated results to understand how each method performs.\n",
    "\n",
    "# # Dictionary to store the results\n",
    "# interpolated_results = {}\n",
    "\n",
    "# # Iterate through all combinations of methods and directions to perform interpolation\n",
    "# for method in methods:\n",
    "#     for direction in directions:\n",
    "#         try:\n",
    "#             interpolated_img = interpolator.simple_interpolate(data.copy(), direction, method)\n",
    "#             key = f\"{method}_{direction}\"\n",
    "#             interpolated_results[key] = interpolated_img\n",
    "#         except Exception as e:\n",
    "#             print(f\"Skipped {method} in {direction} direction due to error: {e}\")\n",
    "\n",
    "# # Let's visualize all the interpolated results to understand how each method performs.\n",
    "# fig, axes = plt.subplots(len(methods), len(directions), figsize=(20, 40))\n",
    "# axes = axes.flatten()\n",
    "\n",
    "# for i, (key, data) in enumerate(interpolated_results.items()):\n",
    "#     ax = axes[i]\n",
    "#     data.plot(ax=ax, add_colorbar=False, cmap='turbo')\n",
    "#     ax.set_title(f\"Method: {key}\")\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (e) Image Smoothing Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib.colors import LogNorm\n",
    "# cmap = plt.cm.turbo\n",
    "# cmap.set_bad('black')\n",
    "\n",
    "waxs_analysis.smooth_image(folded_data, method='gaussian', sigma=1e-6)\n",
    "\n",
    "smoothed_image, (max_x, max_y) = waxs_analysis.normalize_image(img = waxs_analysis.smoothed_img, normalizerecip=False)\n",
    "\n",
    "print ('Maximum Intensity Pixel Coordinate: ', 'x: ', max_x, 'y: ', max_y)\n",
    "\n",
    "# Display the smoothed image with appropriate coordinates using the 'display_image' method\n",
    "# plt = waxs_analysis.display_image(waxs_analysis.smoothed_img, \n",
    "waxs_analysis.display_image(waxs_analysis.smoothed_img, \n",
    "                            title='caked, sin(chi) corrected, normalized, folded, smoothed', \n",
    "                            cmap='turbo')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (f) 2D Image Peak Finding Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "data = None\n",
    "data = folded_data\n",
    "# Find peaks (implement the actual peak-finding logic in the find_peaks method)\n",
    "\n",
    "data = waxs_analysis.find_peaks_DoG (data, \n",
    "                                     sigma1=.4, \n",
    "                                     sigma2=2, \n",
    "                                     threshold=0.008, \n",
    "                                     clustering_method='HDBSCAN', \n",
    "                                     eps=1, \n",
    "                                     min_samples=2, \n",
    "                                     k=3, \n",
    "                                     radius=5)\n",
    "\n",
    "# Display image with peaks\n",
    "waxs_analysis.display_image_with_peaks_and_DoG(data,\n",
    "                                       title='peak finder', \n",
    "                                       cmap='turbo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) 1D Data Reduction (Integration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "cmap = plt.cm.turbo\n",
    "cmap.set_bad('black')\n",
    "plt.close('all')\n",
    "\n",
    "# DA = waxs_analysis.cakedtiff_xr\n",
    "# DA = cakedtiff_sinchi_xr\n",
    "DA = waxs_analysis.smoothed_img\n",
    "# DA, (max_x, max_y) = waxs_analysis.normalize_image(img = waxs_analysis.cakedtiff_xr, normalizerecip=False)\n",
    "\n",
    "colors = cmap(np.linspace(0,1,10))\n",
    "# fig, axs = plt.subplots(1, 2, figsize=(9,3))\n",
    "# plot.line(ax=axs[0], color=colors[i])\n",
    "\n",
    "axs = DA.sum('chi').sel(method='nearest').sel(qr=slice(0.2,3)).plot.line(color=colors[9])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (5) Saving/Exporting & Loading Project Sessions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) Exporting a Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basePath = pathlib.Path('/Users/keithwhite/github_repositories/pyWAXS/examples')\n",
    "zarrPath = basePath.joinpath('output_files/zarr_files')\n",
    "projectName = 'test_project'\n",
    "waxs_analysis.exportzarr(zarrPath=zarrPath, projectName=projectName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Load an Existing Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basePath = pathlib.Path('/Users/keithwhite/github_repositories/pyWAXS/examples')\n",
    "zarrPath = basePath.joinpath('output_files/zarr_files')\n",
    "projectName = 'test_project'\n",
    "waxs_analysis = WAXSReduce(zarrPath = zarrPath, projectName = projectName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Smoothing Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "# Smooth the image using the 'smooth_image' method\n",
    "# smoothed_image = waxs_analysis.smooth_image(waxs_analysis.reciptiff_xr.values, \n",
    "#                                             method='gaussian', \n",
    "#                                             sigma=.05)\n",
    "\n",
    "smoothed_image = waxs_analysis.smooth_image(waxs_analysis.reciptiff_xr, \n",
    "                                            method='gaussian', \n",
    "                                            sigma=1)\n",
    "# smoothed_image = waxs_analysis.normalize_image()\n",
    "# smoothed_image = waxs_analysis.smooth_image(smoothed_image, method='total_variation', sigma=100)\n",
    "\n",
    "# Display the smoothed image with appropriate coordinates using the 'display_image' method\n",
    "waxs_analysis.display_image(smoothed_image, \n",
    "                            title='Smoothed Image', \n",
    "                            cmap='jet')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Signal-to-Noise Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothed_image = waxs_analysis.calculate_SNR(smoothed_image)\n",
    "# waxs_analysis.snrtemp\n",
    "waxs_analysis.reciptiff_xr.SNR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a Class to Compare Simulated (.int) Files to Real Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import find_peaks\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.optimize import minimize\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def gaussian(x, A, mu, sigma):\n",
    "    return A * np.exp(-(x - mu)**2 / (2 * sigma**2))\n",
    "\n",
    "def lorentzian(x, A, mu, gamma):\n",
    "    return A * (1 / np.pi) * (gamma / ((x - mu)**2 + gamma**2))\n",
    "\n",
    "def pseudo_voigt(x, A, mu, sigma, gamma, eta):\n",
    "    return eta * gaussian(x, A, mu, sigma) + (1 - eta) * lorentzian(x, A, mu, gamma)\n",
    "\n",
    "class TraceComparison:\n",
    "    def __init__(self, trace1, trace2):\n",
    "        self.trace1 = trace1\n",
    "        self.trace2 = trace2\n",
    "        self.background_params = None\n",
    "        self.optimized_background = pd.Series(dtype='float64')\n",
    "    \n",
    "    def normalize_to_max(self):\n",
    "        max1 = self.trace1['intensity'].max()\n",
    "        max2 = self.trace2['intensity'].max()\n",
    "        self.trace1.loc[:, 'intensity'] /= max1\n",
    "        self.trace2.loc[:, 'intensity'] /= max2\n",
    "\n",
    "    def normalize_to_baseline(self, q_min, q_max):\n",
    "        baseline1 = self.trace1[(self.trace1['q'] >= q_min) & (self.trace1['q'] <= q_max)]['intensity'].mean()\n",
    "        baseline2 = self.trace2[(self.trace2['q'] >= q_min) & (self.trace2['q'] <= q_max)]['intensity'].mean()\n",
    "        self.trace1['intensity'] /= baseline1\n",
    "        self.trace2['intensity'] /= baseline2\n",
    "\n",
    "    def find_peaks(self, height, distance):\n",
    "        self.peaks1, _ = find_peaks(self.trace1['intensity'], height=height, distance=distance)\n",
    "        self.peaks2, _ = find_peaks(self.trace2['intensity'], height=height, distance=distance)\n",
    "\n",
    "    def compare_peak_widths(self):\n",
    "        self.widths1 = self.trace1.iloc[self.peaks1]['q'].values\n",
    "        self.widths2 = self.trace2.iloc[self.peaks2]['q'].values\n",
    "\n",
    "    def calculate_residual(self):\n",
    "        # Create interpolation functions for the intensity values based on 'q'\n",
    "        f1 = interp1d(self.trace1['q'], self.trace1['intensity'], kind='linear', fill_value=\"extrapolate\")\n",
    "        f2 = interp1d(self.trace2['q'], self.trace2['intensity'], kind='linear', fill_value=\"extrapolate\")\n",
    "\n",
    "        # Create a common 'q' range\n",
    "        common_q = np.linspace(max(self.trace1['q'].min(), self.trace2['q'].min()),\n",
    "                            min(self.trace1['q'].max(), self.trace2['q'].max()),\n",
    "                            num=max(len(self.trace1['q']), len(self.trace2['q'])))\n",
    "\n",
    "        # Interpolate the intensity values to the common 'q' range\n",
    "        common_intensity1 = f1(common_q)\n",
    "        common_intensity2 = f2(common_q)\n",
    "\n",
    "        # Calculate the residual\n",
    "        self.residual = pd.Series(common_intensity1 - common_intensity2, index=common_q, name='residual')\n",
    "\n",
    "    def minimize_residual(self):\n",
    "        min_q = max(self.trace1['q'].min(), self.trace2['q'].min())\n",
    "        max_q = min(self.trace1['q'].max(), self.trace2['q'].max())\n",
    "        common_range = (self.trace1['q'] >= min_q) & (self.trace1['q'] <= max_q)\n",
    "        \n",
    "        x = self.trace1.loc[common_range, 'q']\n",
    "        y1 = self.trace1.loc[common_range, 'intensity']\n",
    "        y2 = self.trace2.loc[common_range, 'intensity']\n",
    "\n",
    "        params, _ = curve_fit(pseudo_voigt, x, y1 - y2)\n",
    "        self.fitted_curve = pseudo_voigt(x, *params)\n",
    "        self.residual = y1 - (y2 + self.fitted_curve)\n",
    "\n",
    "    def optimize_background(self):\n",
    "        def objective(params):\n",
    "            noise_level, slope, intercept = params\n",
    "            background = noise_level + slope * self.trace2['q'] + intercept\n",
    "            modified_trace2 = self.trace2['intensity'] + background\n",
    "            f1 = interp1d(self.trace1['q'], self.trace1['intensity'], kind='linear', fill_value=\"extrapolate\")\n",
    "            f2 = interp1d(self.trace2['q'], modified_trace2, kind='linear', fill_value=\"extrapolate\")\n",
    "\n",
    "            # Define a common 'q' range\n",
    "            common_q = np.linspace(max(self.trace1['q'].min(), self.trace2['q'].min()),\n",
    "                                   min(self.trace1['q'].max(), self.trace2['q'].max()),\n",
    "                                   num=max(len(self.trace1['q']), len(self.trace2['q'])))\n",
    "\n",
    "            residual = f1(common_q) - f2(common_q)\n",
    "            return np.sum(residual ** 2)\n",
    "\n",
    "        initial_guess = [0, 0, 0] if self.background_params is None else self.background_params\n",
    "        result = minimize(objective, initial_guess, method='L-BFGS-B')\n",
    "        self.background_params = result.x\n",
    "\n",
    "        # Apply the optimized background to the trace intensities\n",
    "        self.optimized_background = self.background_params[0] + self.background_params[1] * self.trace2['q'] + self.background_params[2]\n",
    "        self.trace2.loc[:, 'intensity'] += self.optimized_background\n",
    "        self.trace2.loc[:, 'background'] = self.optimized_background  # Store the background in the DataFrame\n",
    "\n",
    "        self.calculate_residual()\n",
    "        \n",
    "    def plot_normalization(self):\n",
    "        plt.figure()\n",
    "        plt.plot(self.trace1['q'], self.trace1['intensity'], label='Trace 1')\n",
    "        plt.plot(self.trace2['q'], self.trace2['intensity'], label='Trace 2')\n",
    "        plt.title('Normalized Traces')\n",
    "        plt.xlabel('q')\n",
    "        plt.ylabel('Intensity')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "    def plot_peaks(self):\n",
    "        plt.figure()\n",
    "        plt.plot(self.trace1['q'], self.trace1['intensity'], label='Trace 1')\n",
    "        plt.plot(self.trace1['q'].iloc[self.peaks1], self.trace1['intensity'].iloc[self.peaks1], 'x', label='Peaks 1')\n",
    "        plt.plot(self.trace2['q'], self.trace2['intensity'], label='Trace 2')\n",
    "        plt.plot(self.trace2['q'].iloc[self.peaks2], self.trace2['intensity'].iloc[self.peaks2], 'o', label='Peaks 2')\n",
    "        plt.title('Peak Positions')\n",
    "        plt.xlabel('q')\n",
    "        plt.ylabel('Intensity')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "    def plot_residual(self):\n",
    "        plt.figure()\n",
    "        plt.plot(self.trace1.loc[self.residual.index, 'q'], self.residual, label='Residual')\n",
    "        plt.title('Residual Between Traces')\n",
    "        plt.xlabel('q')\n",
    "        plt.ylabel('Intensity Difference')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "    def plot_minimization(self):\n",
    "        plt.figure()\n",
    "        plt.plot(self.trace1['q'], self.residual + self.fitted_curve, label='Fitted Curve')\n",
    "        plt.plot(self.trace1['q'], self.residual, label='Original Residual')\n",
    "        plt.title('Minimized Residual')\n",
    "        plt.xlabel('q')\n",
    "        plt.ylabel('Intensity Difference')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    def save_traces_to_csv(self, trace1_filename, trace2_filename, savepath=None):\n",
    "        if savepath:\n",
    "            savepath = Path(savepath)\n",
    "            savepath.mkdir(parents=True, exist_ok=True)\n",
    "            trace1_filepath = savepath / trace1_filename\n",
    "            trace2_filepath = savepath / trace2_filename\n",
    "        else:\n",
    "            trace1_filepath = trace1_filename\n",
    "            trace2_filepath = trace2_filename\n",
    "        \n",
    "        self.trace1.to_csv(trace1_filepath, index=False)\n",
    "        self.trace2.to_csv(trace2_filepath, index=False)\n",
    "\n",
    "    @classmethod\n",
    "    def load_and_plot_traces(cls, trace1_path, trace2_path, savepath=None):\n",
    "        trace1 = pd.read_csv(trace1_path)\n",
    "        trace2 = pd.read_csv(trace2_path)\n",
    "\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        plt.plot(trace1['q'], trace1['intensity'], label='Trace 1')\n",
    "        plt.plot(trace2['q'], trace2['intensity'], label='Trace 2')\n",
    "        plt.xlabel('q')\n",
    "        plt.ylabel('Intensity')\n",
    "        plt.legend()\n",
    "        plt.title('Loaded Traces')\n",
    "        \n",
    "        if savepath:\n",
    "            savepath = Path(savepath)\n",
    "            plt.savefig(savepath)\n",
    "        \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the TraceComparison object\n",
    "bbox_df = pd.DataFrame({'q': waxs_analysis.integrate1d_da.qr.values, 'intensity': waxs_analysis.integrate1d_da.values})\n",
    "\n",
    "# Filter out data below q-value of 0.5\n",
    "bbox_df = bbox_df[bbox_df['q'] >= 0.5]\n",
    "filtered_data = filtered_data[filtered_data['q'] >= 0.5]\n",
    "\n",
    "# Initialize the TraceComparison object and perform calculations\n",
    "comparison = TraceComparison(bbox_df, filtered_data)\n",
    "comparison.normalize_to_max()\n",
    "comparison.calculate_residual()\n",
    "\n",
    "# Plot initial comparison and residual\n",
    "plt.figure(figsize=(6, 10))\n",
    "\n",
    "# Plot the normalized traces\n",
    "plt.subplot(4, 1, 1)\n",
    "plt.plot(comparison.trace1['q'], comparison.trace1['intensity'], label='pygix bbox (Normalized)', color='b')\n",
    "plt.plot(comparison.trace2['q'], comparison.trace2['intensity'], label='Loaded .int File (Normalized)', color='g')\n",
    "plt.title('Initial Comparison of Traces')\n",
    "plt.xlabel('q')\n",
    "plt.ylabel('Intensity')\n",
    "plt.legend()\n",
    "\n",
    "# Plot the initial residual\n",
    "plt.subplot(4, 1, 2)\n",
    "plt.plot(comparison.residual.index, comparison.residual.values, label='Initial Residual', color='r')\n",
    "plt.title('Initial Residual')\n",
    "plt.xlabel('q')\n",
    "plt.ylabel('Intensity Difference')\n",
    "plt.legend()\n",
    "\n",
    "# Optimize the background\n",
    "comparison.optimize_background()\n",
    "\n",
    "# Plot the normalized traces with optimized background\n",
    "plt.subplot(4, 1, 3)\n",
    "plt.plot(comparison.trace1['q'], comparison.trace1['intensity'], label='pygix bbox (Normalized)', color='b')\n",
    "plt.plot(comparison.trace2['q'], comparison.trace2['intensity'], label='Loaded .int File (Normalized)', color='g')\n",
    "plt.title('Comparison of Traces (With Optimized Background)')\n",
    "plt.xlabel('q')\n",
    "plt.ylabel('Intensity')\n",
    "plt.legend()\n",
    "\n",
    "# Plot the new residual\n",
    "plt.subplot(4, 1, 4)\n",
    "plt.plot(comparison.residual.index, comparison.residual.values, label='New Residual', color='r')\n",
    "plt.title('New Residual')\n",
    "plt.xlabel('q')\n",
    "plt.ylabel('Intensity Difference')\n",
    "plt.legend()\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Initialize the TraceComparison object and perform calculations\n",
    "# comparison = TraceComparison(bbox_df, filtered_data)\n",
    "# comparison.normalize_to_max()\n",
    "# comparison.calculate_residual()\n",
    "\n",
    "# # Save the traces for debugging\n",
    "# comparison.save_traces_to_csv('trace1.csv', 'trace2.csv', savepath=savepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct file paths\n",
    "trace1_path = Path('/Users/keithwhite/github_repositories/pyWAXS/examples_local/projects/LaB6_SRM660c_Calib/analysis/simulation/trace1_saved.csv')\n",
    "trace2_path = Path('/Users/keithwhite/github_repositories/pyWAXS/examples_local/projects/LaB6_SRM660c_Calib/analysis/simulation/trace2_saved.csv')\n",
    "\n",
    "# Load and plot the traces\n",
    "TraceComparison.load_and_plot_traces(trace1_path, trace2_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Developing Image Stitching Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required module imports for the ImageStitching class\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "from skimage import io, feature, color\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.feature import corner_harris, corner_peaks\n",
    "import cv2\n",
    "\n",
    "class ImageStitching:\n",
    "    def __init__(self, files: List[Path]):\n",
    "        self.files = files\n",
    "        self.images_original = []\n",
    "        self.images_gray = []\n",
    "        self.keypoints_list = []\n",
    "        self.load_and_preprocess_images()\n",
    "\n",
    "    @staticmethod\n",
    "    def convert_to_8bit(image):\n",
    "        image_norm = (image - np.min(image)) / (np.max(image) - np.min(image))\n",
    "        return (image_norm * 255).astype(np.uint8)\n",
    "    \n",
    "    def load_and_preprocess_images(self):\n",
    "        for file in self.files:\n",
    "            image_original = io.imread(file)\n",
    "            self.images_original.append(image_original)\n",
    "            \n",
    "            if len(image_original.shape) == 3:\n",
    "                image_gray = color.rgb2gray(image_original)\n",
    "            else:\n",
    "                image_gray = image_original\n",
    "            \n",
    "            image_gray = self.convert_to_8bit(image_gray)\n",
    "            self.images_gray.append(image_gray)\n",
    "\n",
    "    def find_sift_keypoints(self):\n",
    "        self.keypoints_list = []\n",
    "        for i, image_gray in enumerate(self.images_gray):\n",
    "            keypoints, _ = self.detect_features(image_gray)\n",
    "            keypoints = np.array([kp.pt for kp in keypoints])\n",
    "            self.keypoints_list.append(keypoints)\n",
    "\n",
    "    @staticmethod\n",
    "    def detect_features(image):\n",
    "        sift = cv2.SIFT_create()\n",
    "        return sift.detectAndCompute(image, None)\n",
    "    \n",
    "    '''\n",
    "    def display_keypoints(self, index: int, title='Image', cmap='turbo'):\n",
    "        img_values = self.images_gray[index]\n",
    "        keypoints = self.keypoints_list[index]\n",
    "        \n",
    "        vmin = np.nanpercentile(img_values, 10)\n",
    "        vmax = np.nanpercentile(img_values, 99)\n",
    "    \n",
    "        plt.imshow(np.flipud(img_values),\n",
    "                   cmap=cmap,\n",
    "                   vmin=vmin,\n",
    "                   vmax=vmax,\n",
    "                   aspect='auto')\n",
    "        \n",
    "        # Draw keypoints on top of the image\n",
    "        for keypoint in keypoints:\n",
    "            x, y = keypoint\n",
    "            plt.scatter(x, y, s=10, c='red', marker='o')\n",
    "        \n",
    "        plt.title(title)\n",
    "        plt.xlabel('x')\n",
    "        plt.ylabel('y')\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "    '''\n",
    "    \n",
    "    def display_keypoints(self, index: int, title='Image', cmap='turbo'):\n",
    "        # plt.close('all')\n",
    "        img_values = self.images_gray[index]\n",
    "        keypoints = self.keypoints_list[index]\n",
    "        \n",
    "        vmin = np.nanpercentile(img_values, 10)\n",
    "        vmax = np.nanpercentile(img_values, 99)\n",
    "    \n",
    "        plt.imshow(np.flipud(img_values),\n",
    "                   cmap=cmap,\n",
    "                   vmin=vmin,\n",
    "                   vmax=vmax,\n",
    "                   aspect='auto')\n",
    "        \n",
    "        # Draw keypoints on top of the image\n",
    "        for keypoint in keypoints:\n",
    "            x, y = keypoint\n",
    "            plt.scatter(x, y, s=10, c='red', marker='o')\n",
    "        \n",
    "        plt.title(title)\n",
    "        plt.xlabel('x')\n",
    "        plt.ylabel('y')\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "    \n",
    "    def find_keypoints(self, n_keypoints: int = 5000, fast_threshold: float = 0.01):\n",
    "        for image_gray in self.images_gray:\n",
    "            orb = feature.ORB(n_keypoints=n_keypoints, fast_threshold=fast_threshold)\n",
    "            orb.detect_and_extract(image_gray)\n",
    "            self.keypoints_list.append(orb.keypoints)\n",
    "\n",
    "    def plot_original(self, index: int):\n",
    "        image = self.images_original[index]\n",
    "        vmin, vmax = np.nanpercentile(image, [10, 99])\n",
    "        plt.imshow(image, cmap='turbo', vmin=vmin, vmax=vmax)\n",
    "        plt.title(\"Original Image\")\n",
    "        plt.show()\n",
    "        \n",
    "    def plot_keypoints(self, index: int):\n",
    "        image = self.images_original[index]\n",
    "        keypoints = self.keypoints_list[index]\n",
    "        vmin, vmax = np.nanpercentile(image, [10, 99])\n",
    "        plt.imshow(image, cmap='turbo', vmin=vmin, vmax=vmax)\n",
    "        plt.plot(keypoints[:, 1], keypoints[:, 0], 'r.', markersize=5)\n",
    "        plt.title(\"Keypoints\")\n",
    "        plt.show()\n",
    "        \n",
    "    def find_harris_keypoints(self, min_distance: int = 5):\n",
    "        self.keypoints_list = []\n",
    "        for image_gray in self.images_gray:\n",
    "            harris_response = corner_harris(image_gray)\n",
    "            keypoints = corner_peaks(harris_response, min_distance=min_distance)\n",
    "            self.keypoints_list.append(keypoints)\n",
    "\n",
    "    def plot_original_with_keypoints(self, index: int):\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "        \n",
    "        # Original Image\n",
    "        image = self.images_original[index]\n",
    "        vmin, vmax = np.nanpercentile(image, [10, 99])\n",
    "        axs[0].imshow(image, cmap='turbo', vmin=vmin, vmax=vmax)\n",
    "        axs[0].set_title(\"Original Image\")\n",
    "        \n",
    "        # Keypoints\n",
    "        keypoints = self.keypoints_list[index]\n",
    "        axs[1].imshow(image, cmap='turbo', vmin=vmin, vmax=vmax)\n",
    "        axs[1].plot(keypoints[:, 1], keypoints[:, 0], 'r.', markersize=5)\n",
    "        axs[1].set_title(\"Keypoints\")\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def plot_sift_keypoints(self, index: int):\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "        \n",
    "        # Original Image\n",
    "        image = self.images_original[index]\n",
    "        vmin, vmax = np.nanpercentile(image, [10, 99])\n",
    "        axs[0].imshow(image, cmap='turbo', vmin=vmin, vmax=vmax)\n",
    "        axs[0].set_title(\"Original Image\")\n",
    "        \n",
    "        # SIFT Keypoints\n",
    "        keypoints = self.keypoints_list[index]\n",
    "        print(f\"Plotting Image {index}: Keypoints shape: {keypoints.shape}\")  # Add debug print\n",
    "        axs[1].imshow(image, cmap='turbo', vmin=vmin, vmax=vmax)\n",
    "        # axs[1].plot(keypoints[:, 0], keypoints[:, 1], 'r.', markersize=5)  # Corrected indexing\n",
    "        axs[1].plot(keypoints[:, 1], keypoints[:, 0], 'r.', markersize=5)\n",
    "        axs[1].set_title(\"SIFT Keypoints\")\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Initialize the class and find keypoints with local file paths for the example\n",
    "files = [\n",
    "    Path(\"/Users/keithwhite/github_repositories/pyWAXS/examples_local/projects/1MAI_3PbI2_DMF_1M_jun23/stitch/sam16_3mai1pbi2_dmf_1m_5scfh_Si_40uL_010_2356.6s_x-0.001_th0.300_10.00s_1116233_maxs.tiff\"),\n",
    "    Path(\"/Users/keithwhite/github_repositories/pyWAXS/examples_local/projects/1MAI_3PbI2_DMF_1M_jun23/stitch/sam16_3mai1pbi2_dmf_1m_5scfh_Si_40uL_010_2461.2s_x-0.001_th0.300_10.00s_1116234_maxs.tiff\")\n",
    "]\n",
    "\n",
    "stitcher_sift = ImageStitching(files)\n",
    "\n",
    "plt.close('all')\n",
    "\n",
    "# Find and visualize SIFT keypoints\n",
    "stitcher_sift.find_sift_keypoints()\n",
    "stitcher_sift.display_keypoints(0, title='Image 1')\n",
    "# stitcher_sift.display_keypoints(1, title='Image 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stitcher_sift.display_keypoints(1, title='Image 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if xfeatures2d module is available\n",
    "sift_available = \"xfeatures2d\" in cv2.__dict__\n",
    "if sift_available:\n",
    "    print(\"SIFT is available in OpenCV.\")\n",
    "else:\n",
    "    print(\"SIFT is not available in OpenCV.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the class and find keypoints with local file paths for the example\n",
    "files = [\n",
    "    Path(\"/Users/keithwhite/github_repositories/pyWAXS/examples_local/projects/1MAI_3PbI2_DMF_1M_jun23/stitch/sam16_3mai1pbi2_dmf_1m_5scfh_Si_40uL_010_2356.6s_x-0.001_th0.300_10.00s_1116233_maxs.tiff\"),\n",
    "    Path(\"/Users/keithwhite/github_repositories/pyWAXS/examples_local/projects/1MAI_3PbI2_DMF_1M_jun23/stitch/sam16_3mai1pbi2_dmf_1m_5scfh_Si_40uL_010_2461.2s_x-0.001_th0.300_10.00s_1116234_maxs.tiff\")\n",
    "]\n",
    "\n",
    "# Initialize the class and find SIFT keypoints\n",
    "stitcher_sift = ImageStitching(files)\n",
    "stitcher_sift.find_sift_keypoints()\n",
    "\n",
    "# Test the new plotting method for SIFT keypoints\n",
    "stitcher_sift.plot_sift_keypoints(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the class and find keypoints with local file paths for the example\n",
    "files = [\n",
    "    Path(\"/Users/keithwhite/github_repositories/pyWAXS/examples_local/projects/1MAI_3PbI2_DMF_1M_jun23/stitch/sam16_3mai1pbi2_dmf_1m_5scfh_Si_40uL_010_2356.6s_x-0.001_th0.300_10.00s_1116233_maxs.tiff\"),\n",
    "    Path(\"/Users/keithwhite/github_repositories/pyWAXS/examples_local/projects/1MAI_3PbI2_DMF_1M_jun23/stitch/sam16_3mai1pbi2_dmf_1m_5scfh_Si_40uL_010_2461.2s_x-0.001_th0.300_10.00s_1116234_maxs.tiff\")\n",
    "]\n",
    "\n",
    "# Initialize the class and find SIFT keypoints\n",
    "stitcher_sift = ImageStitching(files)\n",
    "stitcher_sift.find_sift_keypoints()\n",
    "\n",
    "# Test the new plotting method for SIFT keypoints\n",
    "stitcher_sift.plot_sift_keypoints(0)\n",
    "\n",
    "# Example usage\n",
    "# stitcher_example = ImageStitching(local_files)\n",
    "# stitcher_example.find_keypoints()\n",
    "\n",
    "# Note: The actual images won't be loaded in this environment due to path constraints. This is just for demonstration.\n",
    "# stitcher_example.files\n",
    "# Re-initialize the class and find keypoints with the initially uploaded files (as local files are not accessible here)\n",
    "\n",
    "# Test the plotting methods\n",
    "# stitcher_example.plot_original(0)\n",
    "# stitcher_example.plot_keypoints(0)\n",
    "# stitcher_example.plot_original_with_keypoints(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image Processer Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include the required imports for the class\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Modify the ImageProcessor class to match the given contrast scaling method\n",
    "class ImageProcessor:\n",
    "    @staticmethod\n",
    "    def convert_to_8bit(image):\n",
    "        image_norm = (image - np.min(image)) / (np.max(image) - np.min(image))\n",
    "        return (image_norm * 255).astype(np.uint8)\n",
    "    \n",
    "    @staticmethod\n",
    "    def detect_features(image):\n",
    "        sift = cv2.SIFT_create()\n",
    "        return sift.detectAndCompute(image, None)\n",
    "    \n",
    "    @staticmethod\n",
    "    def display_image(img, ax, title='Image', cmap='turbo'):\n",
    "        if img is None or not isinstance(img, np.ndarray):\n",
    "            raise ValueError(\"The input image is None or not of a compatible type.\")\n",
    "        \n",
    "        img_values = img\n",
    "        if np.all(np.isnan(img_values)) or img_values.size == 0:\n",
    "            raise ValueError(\"The input image is empty or contains only NaN values.\")\n",
    "        \n",
    "        vmin = np.nanpercentile(img_values, 10)\n",
    "        vmax = np.nanpercentile(img_values, 99)\n",
    "        ax.imshow(np.flipud(img_values),\n",
    "                   cmap=cmap,\n",
    "                   vmin=vmin,\n",
    "                   vmax=vmax,\n",
    "                   aspect='auto')\n",
    "        ax.set_title(title)\n",
    "        ax.axis('off')\n",
    "        \n",
    "    def process_and_display_single_image(self, image, title='Image'):\n",
    "        # Convert to 8-bit grayscale\n",
    "        image_8bit = self.convert_to_8bit(image)\n",
    "        \n",
    "        # Detect features (keypoints)\n",
    "        keypoints, _ = self.detect_features(image_8bit)\n",
    "        \n",
    "        # Create a figure with 2 subplots\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "        \n",
    "        # Display the original image in the first subplot\n",
    "        self.display_image(image_8bit, axes[0], title=f'{title} - Original')\n",
    "        \n",
    "        # Display the keypoints in the second subplot\n",
    "        img_keypoints = cv2.drawKeypoints(image_8bit, keypoints, None)\n",
    "        self.display_image(img_keypoints, axes[1], title=f'{title} - {len(keypoints)} Keypoints')\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "# Instantiate the ImageProcessor class\n",
    "processor = ImageProcessor()\n",
    "\n",
    "# Process and display each image one by one\n",
    "for i, img in enumerate(images):\n",
    "    processor.process_and_display_single_image(img, title=f'Image {i+1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the ImageProcessor class\n",
    "processor = ImageProcessor()\n",
    "\n",
    "# Process and display each image one by one\n",
    "for i, img in enumerate(images):\n",
    "    processor.process_and_display_single_image(img, title=f'Image {i+1}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyGIXS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
